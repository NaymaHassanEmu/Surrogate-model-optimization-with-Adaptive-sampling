{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fceaeeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import nan\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import joblib\n",
    "# %run 3.Xfoil_runner_extract_value.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "314ed73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>CL</th>\n",
       "      <th>CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>-0.0086</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>0.5294</td>\n",
       "      <td>0.00733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0045</td>\n",
       "      <td>-0.0035</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>-0.0060</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.6747</td>\n",
       "      <td>0.00947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.0093</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>-0.0113</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>-0.0093</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.4693</td>\n",
       "      <td>0.00959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0093</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0092</td>\n",
       "      <td>0.5034</td>\n",
       "      <td>0.00928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>-0.0039</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>-0.0087</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.00916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-0.0044</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.8012</td>\n",
       "      <td>0.01042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>-0.0009</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.8244</td>\n",
       "      <td>0.00968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.8235</td>\n",
       "      <td>0.00959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.8246</td>\n",
       "      <td>0.00967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.8119</td>\n",
       "      <td>0.00981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1      x2      x3      x4      x5      x6      x7      x8      CL  \\\n",
       "0    0.0084  0.0104 -0.0033 -0.0033 -0.0086  0.0015 -0.0019 -0.0027  0.5294   \n",
       "1   -0.0045 -0.0035  0.0057  0.0062  0.0106 -0.0060  0.0101  0.0037  0.6747   \n",
       "2   -0.0093  0.0038 -0.0083 -0.0113  0.0030 -0.0028 -0.0093  0.0085  0.4693   \n",
       "3    0.0019 -0.0093  0.0067  0.0025 -0.0012  0.0077  0.0026 -0.0092  0.5034   \n",
       "4    0.0045  0.0017  0.0026  0.0050 -0.0039  0.0034 -0.0087  0.0105  0.6249   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "153 -0.0044  0.0119  0.0110  0.0122  0.0077  0.0096  0.0089  0.0023  0.8012   \n",
       "154 -0.0009  0.0126  0.0126  0.0111  0.0116  0.0082  0.0085  0.0053  0.8244   \n",
       "155  0.0001  0.0113  0.0119  0.0129  0.0129  0.0074  0.0071  0.0048  0.8235   \n",
       "156 -0.0005  0.0121  0.0125  0.0118  0.0122  0.0067  0.0090  0.0045  0.8246   \n",
       "157 -0.0017  0.0120  0.0110  0.0122  0.0113  0.0079  0.0077  0.0060  0.8119   \n",
       "\n",
       "          CD  \n",
       "0    0.00733  \n",
       "1    0.00947  \n",
       "2    0.00959  \n",
       "3    0.00928  \n",
       "4    0.00916  \n",
       "..       ...  \n",
       "153  0.01042  \n",
       "154  0.00968  \n",
       "155  0.00959  \n",
       "156  0.00967  \n",
       "157  0.00981  \n",
       "\n",
       "[152 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('new_dataset.xlsx')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df.to_excel('dataset.xlsx')\n",
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "747243e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f00ee668",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8'] ]\n",
    "y = df[['CL', 'CD'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b69a06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>-0.0086</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0045</td>\n",
       "      <td>-0.0035</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>-0.0060</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.0093</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>-0.0113</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>-0.0093</td>\n",
       "      <td>0.0085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0093</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>-0.0039</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>-0.0087</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-0.0044</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>-0.0009</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1      x2      x3      x4      x5      x6      x7      x8\n",
       "0    0.0084  0.0104 -0.0033 -0.0033 -0.0086  0.0015 -0.0019 -0.0027\n",
       "1   -0.0045 -0.0035  0.0057  0.0062  0.0106 -0.0060  0.0101  0.0037\n",
       "2   -0.0093  0.0038 -0.0083 -0.0113  0.0030 -0.0028 -0.0093  0.0085\n",
       "3    0.0019 -0.0093  0.0067  0.0025 -0.0012  0.0077  0.0026 -0.0092\n",
       "4    0.0045  0.0017  0.0026  0.0050 -0.0039  0.0034 -0.0087  0.0105\n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...\n",
       "153 -0.0044  0.0119  0.0110  0.0122  0.0077  0.0096  0.0089  0.0023\n",
       "154 -0.0009  0.0126  0.0126  0.0111  0.0116  0.0082  0.0085  0.0053\n",
       "155  0.0001  0.0113  0.0119  0.0129  0.0129  0.0074  0.0071  0.0048\n",
       "156 -0.0005  0.0121  0.0125  0.0118  0.0122  0.0067  0.0090  0.0045\n",
       "157 -0.0017  0.0120  0.0110  0.0122  0.0113  0.0079  0.0077  0.0060\n",
       "\n",
       "[152 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61e845bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CL</th>\n",
       "      <th>CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5294</td>\n",
       "      <td>0.00733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6747</td>\n",
       "      <td>0.00947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4693</td>\n",
       "      <td>0.00959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5034</td>\n",
       "      <td>0.00928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.00916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.8012</td>\n",
       "      <td>0.01042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.8244</td>\n",
       "      <td>0.00968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.8235</td>\n",
       "      <td>0.00959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.8246</td>\n",
       "      <td>0.00967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.8119</td>\n",
       "      <td>0.00981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CL       CD\n",
       "0    0.5294  0.00733\n",
       "1    0.6747  0.00947\n",
       "2    0.4693  0.00959\n",
       "3    0.5034  0.00928\n",
       "4    0.6249  0.00916\n",
       "..      ...      ...\n",
       "153  0.8012  0.01042\n",
       "154  0.8244  0.00968\n",
       "155  0.8235  0.00959\n",
       "156  0.8246  0.00967\n",
       "157  0.8119  0.00981\n",
       "\n",
       "[152 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2bb1fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "628f7280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mean_absolute_percentage_error(y_true, y_pred):\n",
    "#     y_true = tf.where(tf.equal(y_true, 0.0), 1e-10, y_true)\n",
    "#     ape = tf.abs((y_true - y_pred) / y_true)*100\n",
    "#     ape = tf.where(tf.math.is_finite(ape), ape, 0.0)\n",
    "#     mape = tf.reduce_mean(ape)\n",
    "    \n",
    "#     return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c494d71-9b6f-42e9-b604-7750685321b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def root_mean_squared_error(y_true, y_pred):\n",
    "#     return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b69f480-f990-4239-bb0e-5842c7cdfaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_mape(X,y, model):\n",
    "    predictions = model.predict(X)\n",
    "    y = y = np.array(y)\n",
    "    absolute_errors = np.abs(predictions - y)\n",
    "    percentage_errors = (absolute_errors / np.abs(y)) * 100\n",
    "    mape_Cl = np.mean(percentage_errors[:, 0])  \n",
    "    mape_Cd = np.mean(percentage_errors[:, 1]) \n",
    "    return mape_Cl, mape_Cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "095fe53c-1c75-4a2f-8dce-693754010ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KFOLD_CROSS_VAL(X, y, n_fold, neurons ,activation, loss_func, epoch, batch_size):\n",
    "    kf = KFold(n_splits=n_fold, shuffle=True)\n",
    "    num_rows = 0\n",
    "    num_cols = 4\n",
    "    loss_score = np.empty((num_rows, num_cols))\n",
    "    \n",
    "    for train_index, val_index in kf.split(X, y):\n",
    "        X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "        scaler = StandardScaler()\n",
    "        X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "        X_val_fold = scaler.transform(X_val_fold)\n",
    "        \n",
    "        from tensorflow.keras.optimizers import Adam\n",
    "        optimizer = Adam(learning_rate=0.01)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(neurons, input_dim=8, activation=activation, kernel_regularizer = regularizers.l2(0.01)))\n",
    "        model.add(Dense(2, activation='linear'))\n",
    "        model.compile(loss=loss_func, optimizer=optimizer, metrics=['mse',tf.keras.metrics.RootMeanSquaredError(name='rmse'),'mape'])\n",
    "        model.fit(X_train_fold, y_train_fold, epochs= epoch, batch_size= batch_size)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        loss = model.evaluate(X_val_fold, y_val_fold)\n",
    "        loss_score = np.vstack([loss_score, np.array(loss)])\n",
    "    \n",
    "    # Calculate average accuracy and other metrics if needed\n",
    "    average_loss = np.mean(loss_score, axis=0)\n",
    "    return loss_score, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb68ec90-4b38-418f-bbe3-64adf3c50278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_model(X, y, neurons ,activation, loss_func, epoch, batch_size, validation_split):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    optimizer = Adam(learning_rate=0.01)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=8, activation=activation, kernel_regularizer = regularizers.l2(0.01)))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    model.compile(loss= loss_func, optimizer=optimizer, metrics=['mse',tf.keras.metrics.RootMeanSquaredError(name='rmse'),'mape'])\n",
    "    history = model.fit(X_train, y_train, epochs=epoch, batch_size=batch_size, validation_split=validation_split)\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "\n",
    "    cl_train, cd_train = cal_mape(X_train,y_train, model)\n",
    "    cl_test, cd_test = cal_mape(X_test,y_test, model)\n",
    "    return model, scaler, loss, history, cl_train, cd_train, cl_test, cd_test\n",
    "\n",
    "def DNN_model(X, y, H1_neurons , H2_neurons ,activation, loss_func, epoch, batch_size, validation_split):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    optimizer = Adam(learning_rate=0.01)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(H1_neurons, input_dim=8, activation=activation, kernel_regularizer = regularizers.l2(0.01)))\n",
    "    model.add(Dense(H2_neurons, activation=activation))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    model.compile(loss= loss_func, optimizer=optimizer, metrics=['mse',tf.keras.metrics.RootMeanSquaredError(name='rmse'),'mape'])\n",
    "    history = model.fit(X_train, y_train, epochs=epoch, batch_size=batch_size, validation_split=validation_split)\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "\n",
    "    cl_train, cd_train = cal_mape(X_train,y_train, model)\n",
    "    cl_test, cd_test = cal_mape(X_test,y_test, model)\n",
    "    return model, scaler, loss, history, cl_train, cd_train, cl_test, cd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14463f9e-d08f-4ff2-98dd-fa3c33a08351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Validation_curves(history):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29a4df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "# neurons_list = [4,6,8,10,12,14,16]\n",
    "activation = 'tanh'\n",
    "loss_func = 'mean_absolute_error'\n",
    "epoch = 200\n",
    "batch_size = 16\n",
    "validation_split = 0.2\n",
    "mae= []\n",
    "mse = []\n",
    "RMSE = []\n",
    "mape = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b078dc03-e565-4d35-a43a-3531628022ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 58ms/step - loss: 0.6833 - mse: 0.5603 - rmse: 0.7485 - mape: 2449.6624 - val_loss: 0.5602 - val_mse: 0.3459 - val_rmse: 0.5881 - val_mape: 1854.1350\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4263 - mse: 0.2078 - rmse: 0.4559 - mape: 1418.4398 - val_loss: 0.3511 - val_mse: 0.1204 - val_rmse: 0.3470 - val_mape: 1030.6636\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2469 - mse: 0.0479 - rmse: 0.2189 - mape: 826.6041 - val_loss: 0.2014 - val_mse: 0.0288 - val_rmse: 0.1698 - val_mape: 615.8071\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1978 - mse: 0.0232 - rmse: 0.1522 - mape: 575.5699 - val_loss: 0.1858 - val_mse: 0.0188 - val_rmse: 0.1372 - val_mape: 539.3038\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1867 - mse: 0.0236 - rmse: 0.1535 - mape: 504.0711 - val_loss: 0.1639 - val_mse: 0.0162 - val_rmse: 0.1272 - val_mape: 427.4991\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1635 - mse: 0.0150 - rmse: 0.1225 - mape: 470.1974 - val_loss: 0.1427 - val_mse: 0.0111 - val_rmse: 0.1056 - val_mape: 376.5335\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1293 - mse: 0.0077 - rmse: 0.0876 - mape: 332.0000 - val_loss: 0.1128 - val_mse: 0.0066 - val_rmse: 0.0812 - val_mape: 249.6401\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1195 - mse: 0.0062 - rmse: 0.0788 - mape: 293.2880 - val_loss: 0.1122 - val_mse: 0.0084 - val_rmse: 0.0916 - val_mape: 237.7831\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1020 - mse: 0.0041 - rmse: 0.0638 - mape: 247.5888 - val_loss: 0.0925 - val_mse: 0.0047 - val_rmse: 0.0683 - val_mape: 191.2095\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0923 - mse: 0.0034 - rmse: 0.0587 - mape: 205.7607 - val_loss: 0.0912 - val_mse: 0.0044 - val_rmse: 0.0666 - val_mape: 209.0750\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0849 - mse: 0.0030 - rmse: 0.0548 - mape: 170.9223 - val_loss: 0.0792 - val_mse: 0.0035 - val_rmse: 0.0593 - val_mape: 162.7361\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0744 - mse: 0.0021 - rmse: 0.0461 - mape: 143.5494 - val_loss: 0.0707 - val_mse: 0.0022 - val_rmse: 0.0474 - val_mape: 155.4301\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0710 - mse: 0.0023 - rmse: 0.0478 - mape: 133.6462 - val_loss: 0.0773 - val_mse: 0.0042 - val_rmse: 0.0648 - val_mape: 128.1146\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0688 - mse: 0.0025 - rmse: 0.0499 - mape: 141.1572 - val_loss: 0.0639 - val_mse: 0.0024 - val_rmse: 0.0487 - val_mape: 137.8171\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0601 - mse: 0.0017 - rmse: 0.0409 - mape: 119.4172 - val_loss: 0.0706 - val_mse: 0.0032 - val_rmse: 0.0569 - val_mape: 191.1591\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0565 - mse: 0.0015 - rmse: 0.0387 - mape: 126.1487 - val_loss: 0.0510 - val_mse: 0.0013 - val_rmse: 0.0357 - val_mape: 95.3254\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0505 - mse: 0.0011 - rmse: 0.0325 - mape: 105.5118 - val_loss: 0.0522 - val_mse: 0.0016 - val_rmse: 0.0397 - val_mape: 113.1793\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0496 - mse: 0.0011 - rmse: 0.0331 - mape: 92.8624 - val_loss: 0.0478 - val_mse: 0.0013 - val_rmse: 0.0361 - val_mape: 109.4776\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0484 - mse: 0.0011 - rmse: 0.0338 - mape: 90.9731 - val_loss: 0.0453 - val_mse: 0.0012 - val_rmse: 0.0349 - val_mape: 85.3407\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0446 - mse: 9.2519e-04 - rmse: 0.0304 - mape: 88.8213 - val_loss: 0.0412 - val_mse: 9.5129e-04 - val_rmse: 0.0308 - val_mape: 72.1508\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0404 - mse: 8.0170e-04 - rmse: 0.0283 - mape: 73.8840 - val_loss: 0.0440 - val_mse: 0.0014 - val_rmse: 0.0377 - val_mape: 85.1476\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0432 - mse: 0.0012 - rmse: 0.0341 - mape: 88.7848 - val_loss: 0.0408 - val_mse: 9.1042e-04 - val_rmse: 0.0302 - val_mape: 109.9636\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0412 - mse: 0.0011 - rmse: 0.0325 - mape: 81.7591 - val_loss: 0.0536 - val_mse: 0.0029 - val_rmse: 0.0539 - val_mape: 90.2767\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0448 - mse: 0.0017 - rmse: 0.0411 - mape: 77.9780 - val_loss: 0.0506 - val_mse: 0.0021 - val_rmse: 0.0461 - val_mape: 103.1198\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0456 - mse: 0.0016 - rmse: 0.0401 - mape: 107.6532 - val_loss: 0.0490 - val_mse: 0.0019 - val_rmse: 0.0440 - val_mape: 112.6695\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0409 - mse: 0.0014 - rmse: 0.0380 - mape: 73.4280 - val_loss: 0.0343 - val_mse: 7.4063e-04 - val_rmse: 0.0272 - val_mape: 80.3573\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0377 - mse: 0.0012 - rmse: 0.0350 - mape: 64.2485 - val_loss: 0.0338 - val_mse: 8.3647e-04 - val_rmse: 0.0289 - val_mape: 72.1883\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0353 - mse: 0.0011 - rmse: 0.0332 - mape: 49.9527 - val_loss: 0.0383 - val_mse: 0.0014 - val_rmse: 0.0380 - val_mape: 63.1007\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0344 - mse: 0.0011 - rmse: 0.0334 - mape: 46.6829 - val_loss: 0.0360 - val_mse: 0.0012 - val_rmse: 0.0345 - val_mape: 51.4126\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0337 - mse: 0.0011 - rmse: 0.0327 - mape: 48.2483 - val_loss: 0.0331 - val_mse: 0.0011 - val_rmse: 0.0328 - val_mape: 52.4099\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0314 - mse: 8.6631e-04 - rmse: 0.0294 - mape: 68.9918 - val_loss: 0.0343 - val_mse: 9.8910e-04 - val_rmse: 0.0314 - val_mape: 88.2597\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0285 - mse: 6.7319e-04 - rmse: 0.0259 - mape: 67.3289 - val_loss: 0.0278 - val_mse: 6.2285e-04 - val_rmse: 0.0250 - val_mape: 58.2598\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0278 - mse: 5.4459e-04 - rmse: 0.0233 - mape: 67.2593 - val_loss: 0.0301 - val_mse: 0.0010 - val_rmse: 0.0320 - val_mape: 56.2065\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0281 - mse: 7.0429e-04 - rmse: 0.0265 - mape: 65.5774 - val_loss: 0.0262 - val_mse: 5.6398e-04 - val_rmse: 0.0237 - val_mape: 56.6784\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0254 - mse: 6.5143e-04 - rmse: 0.0255 - mape: 41.0459 - val_loss: 0.0238 - val_mse: 5.8863e-04 - val_rmse: 0.0243 - val_mape: 36.9094\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0228 - mse: 4.3473e-04 - rmse: 0.0209 - mape: 50.2739 - val_loss: 0.0206 - val_mse: 3.9129e-04 - val_rmse: 0.0198 - val_mape: 34.4613\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0220 - mse: 4.3665e-04 - rmse: 0.0209 - mape: 47.2602 - val_loss: 0.0198 - val_mse: 3.2177e-04 - val_rmse: 0.0179 - val_mape: 51.8177\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0234 - mse: 5.1462e-04 - rmse: 0.0227 - mape: 61.9902 - val_loss: 0.0207 - val_mse: 3.5104e-04 - val_rmse: 0.0187 - val_mape: 57.8809\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0239 - mse: 5.4066e-04 - rmse: 0.0233 - mape: 68.9620 - val_loss: 0.0249 - val_mse: 6.8565e-04 - val_rmse: 0.0262 - val_mape: 54.4960\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0271 - mse: 8.2191e-04 - rmse: 0.0287 - mape: 82.9653 - val_loss: 0.0210 - val_mse: 4.9408e-04 - val_rmse: 0.0222 - val_mape: 54.1276\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0199 - mse: 3.6731e-04 - rmse: 0.0192 - mape: 48.4672 - val_loss: 0.0186 - val_mse: 3.1341e-04 - val_rmse: 0.0177 - val_mape: 40.1799\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0214 - mse: 5.0527e-04 - rmse: 0.0225 - mape: 42.3963 - val_loss: 0.0220 - val_mse: 6.4789e-04 - val_rmse: 0.0255 - val_mape: 26.6083\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0208 - mse: 5.4178e-04 - rmse: 0.0233 - mape: 32.2140 - val_loss: 0.0209 - val_mse: 5.5909e-04 - val_rmse: 0.0236 - val_mape: 39.0740\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0193 - mse: 4.0917e-04 - rmse: 0.0202 - mape: 43.7624 - val_loss: 0.0150 - val_mse: 2.1039e-04 - val_rmse: 0.0145 - val_mape: 34.3434\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0202 - mse: 5.2471e-04 - rmse: 0.0229 - mape: 42.9192 - val_loss: 0.0196 - val_mse: 4.8118e-04 - val_rmse: 0.0219 - val_mape: 43.9978\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0196 - mse: 4.2156e-04 - rmse: 0.0205 - mape: 49.5045 - val_loss: 0.0190 - val_mse: 4.9482e-04 - val_rmse: 0.0222 - val_mape: 37.3237\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0203 - mse: 5.0277e-04 - rmse: 0.0224 - mape: 48.5617 - val_loss: 0.0210 - val_mse: 5.4288e-04 - val_rmse: 0.0233 - val_mape: 49.7312\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0198 - mse: 5.0071e-04 - rmse: 0.0224 - mape: 43.3117 - val_loss: 0.0167 - val_mse: 4.3766e-04 - val_rmse: 0.0209 - val_mape: 22.4800\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0186 - mse: 5.0410e-04 - rmse: 0.0225 - mape: 30.0712 - val_loss: 0.0216 - val_mse: 6.7490e-04 - val_rmse: 0.0260 - val_mape: 35.9341\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0195 - mse: 5.4066e-04 - rmse: 0.0233 - mape: 35.7865 - val_loss: 0.0183 - val_mse: 3.9838e-04 - val_rmse: 0.0200 - val_mape: 45.6644\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0182 - mse: 5.0644e-04 - rmse: 0.0225 - mape: 35.7019 - val_loss: 0.0196 - val_mse: 5.6093e-04 - val_rmse: 0.0237 - val_mape: 27.7021\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0191 - mse: 5.3139e-04 - rmse: 0.0231 - mape: 44.4711 - val_loss: 0.0174 - val_mse: 4.7957e-04 - val_rmse: 0.0219 - val_mape: 27.4164\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0208 - mse: 6.8135e-04 - rmse: 0.0261 - mape: 37.3521 - val_loss: 0.0185 - val_mse: 5.1366e-04 - val_rmse: 0.0227 - val_mape: 33.3957\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0221 - mse: 8.3082e-04 - rmse: 0.0288 - mape: 36.7474 - val_loss: 0.0170 - val_mse: 4.8212e-04 - val_rmse: 0.0220 - val_mape: 15.9120\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0180 - mse: 6.1873e-04 - rmse: 0.0249 - mape: 26.3185 - val_loss: 0.0175 - val_mse: 4.0338e-04 - val_rmse: 0.0201 - val_mape: 43.7118\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0188 - mse: 5.9529e-04 - rmse: 0.0244 - mape: 31.4801 - val_loss: 0.0176 - val_mse: 5.1476e-04 - val_rmse: 0.0227 - val_mape: 24.8133\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0192 - mse: 6.3674e-04 - rmse: 0.0252 - mape: 33.1221 - val_loss: 0.0195 - val_mse: 6.5898e-04 - val_rmse: 0.0257 - val_mape: 23.2736\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0161 - mse: 4.2434e-04 - rmse: 0.0206 - mape: 27.1208 - val_loss: 0.0171 - val_mse: 4.3137e-04 - val_rmse: 0.0208 - val_mape: 47.7859\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0191 - mse: 6.2502e-04 - rmse: 0.0250 - mape: 34.0293 - val_loss: 0.0132 - val_mse: 3.1897e-04 - val_rmse: 0.0179 - val_mape: 20.2408\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0164 - mse: 4.7586e-04 - rmse: 0.0218 - mape: 38.6086 - val_loss: 0.0143 - val_mse: 3.4841e-04 - val_rmse: 0.0187 - val_mape: 27.7302\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0146 - mse: 3.2983e-04 - rmse: 0.0182 - mape: 30.6470 - val_loss: 0.0170 - val_mse: 4.6421e-04 - val_rmse: 0.0215 - val_mape: 54.1897\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0154 - mse: 3.6952e-04 - rmse: 0.0192 - mape: 40.0997 - val_loss: 0.0104 - val_mse: 2.1385e-04 - val_rmse: 0.0146 - val_mape: 12.3921\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0148 - mse: 3.5999e-04 - rmse: 0.0190 - mape: 36.3498 - val_loss: 0.0161 - val_mse: 4.0197e-04 - val_rmse: 0.0200 - val_mape: 38.1110\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0143 - mse: 3.1372e-04 - rmse: 0.0177 - mape: 31.8072 - val_loss: 0.0125 - val_mse: 2.5521e-04 - val_rmse: 0.0160 - val_mape: 26.4490\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0156 - mse: 4.0168e-04 - rmse: 0.0200 - mape: 29.7392 - val_loss: 0.0130 - val_mse: 2.9373e-04 - val_rmse: 0.0171 - val_mape: 28.6753\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0142 - mse: 4.0072e-04 - rmse: 0.0200 - mape: 24.7881 - val_loss: 0.0134 - val_mse: 3.3050e-04 - val_rmse: 0.0182 - val_mape: 21.3054\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0166 - mse: 5.9453e-04 - rmse: 0.0244 - mape: 23.2489 - val_loss: 0.0186 - val_mse: 7.7294e-04 - val_rmse: 0.0278 - val_mape: 34.3953\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0169 - mse: 5.3397e-04 - rmse: 0.0231 - mape: 32.0034 - val_loss: 0.0132 - val_mse: 3.0687e-04 - val_rmse: 0.0175 - val_mape: 23.3709\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0156 - mse: 4.6055e-04 - rmse: 0.0215 - mape: 32.4809 - val_loss: 0.0167 - val_mse: 4.9845e-04 - val_rmse: 0.0223 - val_mape: 32.0831\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0175 - mse: 6.5095e-04 - rmse: 0.0255 - mape: 24.6432 - val_loss: 0.0145 - val_mse: 3.5472e-04 - val_rmse: 0.0188 - val_mape: 28.9954\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0165 - mse: 5.1257e-04 - rmse: 0.0226 - mape: 30.0520 - val_loss: 0.0193 - val_mse: 8.1098e-04 - val_rmse: 0.0285 - val_mape: 24.0961\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0175 - mse: 5.6676e-04 - rmse: 0.0238 - mape: 35.8666 - val_loss: 0.0133 - val_mse: 3.5149e-04 - val_rmse: 0.0187 - val_mape: 18.6714\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0150 - mse: 4.1109e-04 - rmse: 0.0203 - mape: 28.4719 - val_loss: 0.0116 - val_mse: 2.8420e-04 - val_rmse: 0.0169 - val_mape: 13.5675\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0124 - mse: 3.1636e-04 - rmse: 0.0178 - mape: 23.0677 - val_loss: 0.0116 - val_mse: 2.9661e-04 - val_rmse: 0.0172 - val_mape: 20.4229\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0130 - mse: 3.5428e-04 - rmse: 0.0188 - mape: 28.9680 - val_loss: 0.0104 - val_mse: 2.1991e-04 - val_rmse: 0.0148 - val_mape: 20.0052\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0136 - mse: 3.5148e-04 - rmse: 0.0187 - mape: 24.3802 - val_loss: 0.0130 - val_mse: 3.6440e-04 - val_rmse: 0.0191 - val_mape: 19.0473\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0126 - mse: 3.7305e-04 - rmse: 0.0193 - mape: 17.2690 - val_loss: 0.0113 - val_mse: 2.7050e-04 - val_rmse: 0.0164 - val_mape: 18.2106\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0134 - mse: 3.6351e-04 - rmse: 0.0191 - mape: 21.4383 - val_loss: 0.0146 - val_mse: 4.4025e-04 - val_rmse: 0.0210 - val_mape: 23.1571\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0135 - mse: 3.4593e-04 - rmse: 0.0186 - mape: 24.6494 - val_loss: 0.0148 - val_mse: 4.1963e-04 - val_rmse: 0.0205 - val_mape: 25.2063\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0139 - mse: 3.6649e-04 - rmse: 0.0191 - mape: 21.8847 - val_loss: 0.0108 - val_mse: 2.1925e-04 - val_rmse: 0.0148 - val_mape: 14.4557\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0125 - mse: 3.2826e-04 - rmse: 0.0181 - mape: 18.7676 - val_loss: 0.0133 - val_mse: 4.0862e-04 - val_rmse: 0.0202 - val_mape: 19.6167\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0141 - mse: 4.1077e-04 - rmse: 0.0203 - mape: 22.3796 - val_loss: 0.0127 - val_mse: 3.0544e-04 - val_rmse: 0.0175 - val_mape: 23.4522\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0140 - mse: 3.8138e-04 - rmse: 0.0195 - mape: 24.9168 - val_loss: 0.0178 - val_mse: 7.7848e-04 - val_rmse: 0.0279 - val_mape: 15.8887\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0129 - mse: 3.6259e-04 - rmse: 0.0190 - mape: 16.7103 - val_loss: 0.0118 - val_mse: 3.2044e-04 - val_rmse: 0.0179 - val_mape: 12.5601\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0117 - mse: 2.9960e-04 - rmse: 0.0173 - mape: 19.5506 - val_loss: 0.0107 - val_mse: 2.1283e-04 - val_rmse: 0.0146 - val_mape: 22.8123\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0126 - mse: 3.2430e-04 - rmse: 0.0180 - mape: 25.1529 - val_loss: 0.0138 - val_mse: 3.5899e-04 - val_rmse: 0.0189 - val_mape: 24.4945\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0122 - mse: 3.0084e-04 - rmse: 0.0173 - mape: 20.2261 - val_loss: 0.0146 - val_mse: 3.9618e-04 - val_rmse: 0.0199 - val_mape: 29.8685\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0118 - mse: 2.8463e-04 - rmse: 0.0169 - mape: 19.3102 - val_loss: 0.0122 - val_mse: 3.6873e-04 - val_rmse: 0.0192 - val_mape: 10.8690\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0119 - mse: 3.0888e-04 - rmse: 0.0176 - mape: 18.4523 - val_loss: 0.0120 - val_mse: 2.8700e-04 - val_rmse: 0.0169 - val_mape: 15.7054\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0120 - mse: 3.1197e-04 - rmse: 0.0177 - mape: 16.8518 - val_loss: 0.0162 - val_mse: 6.3766e-04 - val_rmse: 0.0253 - val_mape: 13.4984\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0126 - mse: 3.4533e-04 - rmse: 0.0186 - mape: 15.0780 - val_loss: 0.0122 - val_mse: 2.6503e-04 - val_rmse: 0.0163 - val_mape: 31.5886\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0145 - mse: 4.8367e-04 - rmse: 0.0220 - mape: 21.8789 - val_loss: 0.0147 - val_mse: 4.1819e-04 - val_rmse: 0.0204 - val_mape: 21.6620\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0128 - mse: 3.4553e-04 - rmse: 0.0186 - mape: 20.9984 - val_loss: 0.0108 - val_mse: 2.3207e-04 - val_rmse: 0.0152 - val_mape: 25.7034\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0119 - mse: 2.9510e-04 - rmse: 0.0172 - mape: 22.2493 - val_loss: 0.0140 - val_mse: 3.8406e-04 - val_rmse: 0.0196 - val_mape: 33.8045\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0121 - mse: 2.7507e-04 - rmse: 0.0166 - mape: 24.5969 - val_loss: 0.0138 - val_mse: 3.8518e-04 - val_rmse: 0.0196 - val_mape: 21.4401\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0110 - mse: 2.5300e-04 - rmse: 0.0159 - mape: 19.1208 - val_loss: 0.0091 - val_mse: 1.7221e-04 - val_rmse: 0.0131 - val_mape: 14.0452\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0102 - mse: 2.6316e-04 - rmse: 0.0162 - mape: 13.0317 - val_loss: 0.0120 - val_mse: 2.7940e-04 - val_rmse: 0.0167 - val_mape: 19.6728\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0115 - mse: 2.7506e-04 - rmse: 0.0166 - mape: 14.2807 - val_loss: 0.0119 - val_mse: 3.4254e-04 - val_rmse: 0.0185 - val_mape: 15.0472\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0129 - mse: 3.7496e-04 - rmse: 0.0194 - mape: 15.0145 - val_loss: 0.0128 - val_mse: 3.5082e-04 - val_rmse: 0.0187 - val_mape: 14.6579\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0142 - mse: 4.4648e-04 - rmse: 0.0211 - mape: 18.0110 - val_loss: 0.0137 - val_mse: 4.6855e-04 - val_rmse: 0.0216 - val_mape: 12.3535\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0125 - mse: 4.2231e-04 - rmse: 0.0206 - mape: 9.0354 - val_loss: 0.0103 - val_mse: 2.5273e-04 - val_rmse: 0.0159 - val_mape: 11.3667\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0104 - mse: 2.5477e-04 - rmse: 0.0160 - mape: 9.0533 - val_loss: 0.0118 - val_mse: 3.0431e-04 - val_rmse: 0.0174 - val_mape: 6.8168\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0109 - mse: 3.0422e-04 - rmse: 0.0174 - mape: 7.0116 - val_loss: 0.0106 - val_mse: 3.0152e-04 - val_rmse: 0.0174 - val_mape: 5.2519\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0116 - mse: 3.1362e-04 - rmse: 0.0177 - mape: 7.9012 - val_loss: 0.0103 - val_mse: 3.0195e-04 - val_rmse: 0.0174 - val_mape: 7.1839\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0113 - mse: 2.8887e-04 - rmse: 0.0170 - mape: 9.7755 - val_loss: 0.0092 - val_mse: 2.2334e-04 - val_rmse: 0.0149 - val_mape: 7.2627\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0110 - mse: 2.4316e-04 - rmse: 0.0156 - mape: 21.4829 - val_loss: 0.0102 - val_mse: 2.7700e-04 - val_rmse: 0.0166 - val_mape: 7.7391\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0127 - mse: 3.1473e-04 - rmse: 0.0177 - mape: 23.2939 - val_loss: 0.0095 - val_mse: 2.1108e-04 - val_rmse: 0.0145 - val_mape: 10.6178\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0101 - mse: 2.4213e-04 - rmse: 0.0156 - mape: 15.1437 - val_loss: 0.0097 - val_mse: 1.7310e-04 - val_rmse: 0.0132 - val_mape: 23.8675\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0113 - mse: 2.5433e-04 - rmse: 0.0159 - mape: 20.9388 - val_loss: 0.0148 - val_mse: 4.0815e-04 - val_rmse: 0.0202 - val_mape: 28.2519\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0129 - mse: 3.0218e-04 - rmse: 0.0174 - mape: 29.5799 - val_loss: 0.0100 - val_mse: 2.4562e-04 - val_rmse: 0.0157 - val_mape: 13.4289\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0127 - mse: 3.1364e-04 - rmse: 0.0177 - mape: 30.9200 - val_loss: 0.0127 - val_mse: 2.5006e-04 - val_rmse: 0.0158 - val_mape: 41.1846\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0120 - mse: 3.0294e-04 - rmse: 0.0174 - mape: 25.5483 - val_loss: 0.0140 - val_mse: 3.0665e-04 - val_rmse: 0.0175 - val_mape: 43.4586\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0115 - mse: 2.3699e-04 - rmse: 0.0154 - mape: 25.5748 - val_loss: 0.0174 - val_mse: 5.9787e-04 - val_rmse: 0.0245 - val_mape: 33.6183\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0143 - mse: 4.0300e-04 - rmse: 0.0201 - mape: 28.4514 - val_loss: 0.0145 - val_mse: 4.8893e-04 - val_rmse: 0.0221 - val_mape: 15.7845\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0119 - mse: 2.8482e-04 - rmse: 0.0169 - mape: 21.7509 - val_loss: 0.0127 - val_mse: 4.1768e-04 - val_rmse: 0.0204 - val_mape: 14.5014\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0117 - mse: 3.2946e-04 - rmse: 0.0182 - mape: 14.2983 - val_loss: 0.0117 - val_mse: 2.6821e-04 - val_rmse: 0.0164 - val_mape: 21.6241\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0121 - mse: 3.0265e-04 - rmse: 0.0174 - mape: 19.1690 - val_loss: 0.0120 - val_mse: 3.4191e-04 - val_rmse: 0.0185 - val_mape: 17.2520\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0119 - mse: 2.8098e-04 - rmse: 0.0168 - mape: 24.8508 - val_loss: 0.0118 - val_mse: 2.5493e-04 - val_rmse: 0.0160 - val_mape: 18.9368\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0119 - mse: 3.2829e-04 - rmse: 0.0181 - mape: 11.5469 - val_loss: 0.0105 - val_mse: 2.2590e-04 - val_rmse: 0.0150 - val_mape: 15.8601\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0127 - mse: 3.3926e-04 - rmse: 0.0184 - mape: 19.7091 - val_loss: 0.0141 - val_mse: 3.2946e-04 - val_rmse: 0.0182 - val_mape: 41.1730\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0126 - mse: 3.6069e-04 - rmse: 0.0190 - mape: 22.5525 - val_loss: 0.0119 - val_mse: 2.9673e-04 - val_rmse: 0.0172 - val_mape: 17.7652\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0104 - mse: 2.4525e-04 - rmse: 0.0157 - mape: 14.1274 - val_loss: 0.0089 - val_mse: 1.9369e-04 - val_rmse: 0.0139 - val_mape: 10.8370\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0095 - mse: 2.0827e-04 - rmse: 0.0144 - mape: 10.5340 - val_loss: 0.0093 - val_mse: 2.0284e-04 - val_rmse: 0.0142 - val_mape: 8.8516\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0114 - mse: 3.2862e-04 - rmse: 0.0181 - mape: 9.2157 - val_loss: 0.0109 - val_mse: 2.8028e-04 - val_rmse: 0.0167 - val_mape: 6.1004\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0099 - mse: 2.3028e-04 - rmse: 0.0152 - mape: 7.8086 - val_loss: 0.0116 - val_mse: 3.0386e-04 - val_rmse: 0.0174 - val_mape: 7.5874\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0102 - mse: 2.2853e-04 - rmse: 0.0151 - mape: 11.6302 - val_loss: 0.0102 - val_mse: 2.0462e-04 - val_rmse: 0.0143 - val_mape: 11.9258\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0114 - mse: 2.8054e-04 - rmse: 0.0167 - mape: 13.1692 - val_loss: 0.0128 - val_mse: 3.7101e-04 - val_rmse: 0.0193 - val_mape: 16.4210\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0111 - mse: 2.8815e-04 - rmse: 0.0170 - mape: 10.9718 - val_loss: 0.0096 - val_mse: 2.0882e-04 - val_rmse: 0.0145 - val_mape: 14.7181\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0105 - mse: 2.5089e-04 - rmse: 0.0158 - mape: 14.1841 - val_loss: 0.0111 - val_mse: 2.8486e-04 - val_rmse: 0.0169 - val_mape: 5.7119\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0113 - mse: 2.4979e-04 - rmse: 0.0158 - mape: 16.8455 - val_loss: 0.0089 - val_mse: 1.4190e-04 - val_rmse: 0.0119 - val_mape: 19.8354\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0121 - mse: 3.0066e-04 - rmse: 0.0173 - mape: 25.3955 - val_loss: 0.0115 - val_mse: 3.6342e-04 - val_rmse: 0.0191 - val_mape: 11.8121\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0117 - mse: 3.0427e-04 - rmse: 0.0174 - mape: 16.7497 - val_loss: 0.0108 - val_mse: 2.3520e-04 - val_rmse: 0.0153 - val_mape: 16.1852\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0119 - mse: 3.0803e-04 - rmse: 0.0176 - mape: 13.2733 - val_loss: 0.0087 - val_mse: 1.6145e-04 - val_rmse: 0.0127 - val_mape: 9.4163\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0094 - mse: 2.0814e-04 - rmse: 0.0144 - mape: 8.1102 - val_loss: 0.0105 - val_mse: 2.9169e-04 - val_rmse: 0.0171 - val_mape: 7.1393\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0097 - mse: 2.2888e-04 - rmse: 0.0151 - mape: 6.8481 - val_loss: 0.0101 - val_mse: 2.3859e-04 - val_rmse: 0.0154 - val_mape: 14.9537\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0114 - mse: 2.9391e-04 - rmse: 0.0171 - mape: 14.6517 - val_loss: 0.0092 - val_mse: 1.8367e-04 - val_rmse: 0.0136 - val_mape: 12.9709\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0105 - mse: 2.4843e-04 - rmse: 0.0158 - mape: 16.0738 - val_loss: 0.0113 - val_mse: 3.0010e-04 - val_rmse: 0.0173 - val_mape: 15.1175\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0104 - mse: 2.5640e-04 - rmse: 0.0160 - mape: 12.6482 - val_loss: 0.0104 - val_mse: 2.0231e-04 - val_rmse: 0.0142 - val_mape: 14.5345\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0108 - mse: 2.3681e-04 - rmse: 0.0154 - mape: 13.2749 - val_loss: 0.0121 - val_mse: 3.1984e-04 - val_rmse: 0.0179 - val_mape: 14.0924\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0104 - mse: 2.6421e-04 - rmse: 0.0163 - mape: 9.4211 - val_loss: 0.0127 - val_mse: 3.7068e-04 - val_rmse: 0.0193 - val_mape: 14.0068\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0117 - mse: 2.9991e-04 - rmse: 0.0173 - mape: 15.7116 - val_loss: 0.0157 - val_mse: 5.2521e-04 - val_rmse: 0.0229 - val_mape: 28.1840\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0127 - mse: 3.6761e-04 - rmse: 0.0192 - mape: 20.1320 - val_loss: 0.0122 - val_mse: 2.2470e-04 - val_rmse: 0.0150 - val_mape: 29.1386\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0108 - mse: 2.3539e-04 - rmse: 0.0153 - mape: 22.0965 - val_loss: 0.0120 - val_mse: 2.7324e-04 - val_rmse: 0.0165 - val_mape: 23.1972\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0114 - mse: 2.6439e-04 - rmse: 0.0163 - mape: 20.2013 - val_loss: 0.0140 - val_mse: 3.4847e-04 - val_rmse: 0.0187 - val_mape: 40.8014\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0142 - mse: 3.8476e-04 - rmse: 0.0196 - mape: 38.4721 - val_loss: 0.0155 - val_mse: 4.4374e-04 - val_rmse: 0.0211 - val_mape: 44.8007\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0120 - mse: 2.6619e-04 - rmse: 0.0163 - mape: 31.3139 - val_loss: 0.0148 - val_mse: 3.7035e-04 - val_rmse: 0.0192 - val_mape: 27.7825\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0138 - mse: 3.5094e-04 - rmse: 0.0187 - mape: 30.9014 - val_loss: 0.0145 - val_mse: 3.2086e-04 - val_rmse: 0.0179 - val_mape: 42.9643\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0121 - mse: 2.7743e-04 - rmse: 0.0167 - mape: 29.1418 - val_loss: 0.0120 - val_mse: 2.5709e-04 - val_rmse: 0.0160 - val_mape: 28.2480\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0124 - mse: 2.7853e-04 - rmse: 0.0167 - mape: 31.2235 - val_loss: 0.0124 - val_mse: 3.0129e-04 - val_rmse: 0.0174 - val_mape: 26.3762\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0119 - mse: 2.8138e-04 - rmse: 0.0168 - mape: 20.8488 - val_loss: 0.0092 - val_mse: 1.3665e-04 - val_rmse: 0.0117 - val_mape: 21.4438\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0104 - mse: 2.2911e-04 - rmse: 0.0151 - mape: 13.3355 - val_loss: 0.0088 - val_mse: 1.8538e-04 - val_rmse: 0.0136 - val_mape: 12.4042\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0102 - mse: 2.3812e-04 - rmse: 0.0154 - mape: 11.2984 - val_loss: 0.0103 - val_mse: 2.2553e-04 - val_rmse: 0.0150 - val_mape: 13.1878\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0121 - mse: 3.6808e-04 - rmse: 0.0192 - mape: 12.1428 - val_loss: 0.0108 - val_mse: 3.1292e-04 - val_rmse: 0.0177 - val_mape: 9.9428\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0107 - mse: 2.5446e-04 - rmse: 0.0160 - mape: 9.8831 - val_loss: 0.0106 - val_mse: 2.4023e-04 - val_rmse: 0.0155 - val_mape: 18.6167\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0130 - mse: 3.6191e-04 - rmse: 0.0190 - mape: 23.8787 - val_loss: 0.0088 - val_mse: 1.8527e-04 - val_rmse: 0.0136 - val_mape: 7.9257\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0113 - mse: 2.2259e-04 - rmse: 0.0149 - mape: 27.3440 - val_loss: 0.0133 - val_mse: 2.6344e-04 - val_rmse: 0.0162 - val_mape: 40.9292\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0125 - mse: 2.6781e-04 - rmse: 0.0164 - mape: 34.7785 - val_loss: 0.0102 - val_mse: 1.8833e-04 - val_rmse: 0.0137 - val_mape: 27.6556\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0112 - mse: 2.5914e-04 - rmse: 0.0161 - mape: 16.7182 - val_loss: 0.0092 - val_mse: 1.8589e-04 - val_rmse: 0.0136 - val_mape: 9.6366\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0098 - mse: 2.2002e-04 - rmse: 0.0148 - mape: 10.8174 - val_loss: 0.0100 - val_mse: 2.0970e-04 - val_rmse: 0.0145 - val_mape: 15.2744\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0097 - mse: 2.2489e-04 - rmse: 0.0150 - mape: 11.1198 - val_loss: 0.0089 - val_mse: 2.3264e-04 - val_rmse: 0.0153 - val_mape: 5.0753\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0101 - mse: 2.2706e-04 - rmse: 0.0151 - mape: 9.2915 - val_loss: 0.0100 - val_mse: 2.1255e-04 - val_rmse: 0.0146 - val_mape: 9.7823\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0102 - mse: 2.1384e-04 - rmse: 0.0146 - mape: 10.5947 - val_loss: 0.0110 - val_mse: 2.5371e-04 - val_rmse: 0.0159 - val_mape: 15.7762\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0105 - mse: 2.6168e-04 - rmse: 0.0162 - mape: 10.1084 - val_loss: 0.0093 - val_mse: 1.9274e-04 - val_rmse: 0.0139 - val_mape: 9.7850\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0106 - mse: 2.3859e-04 - rmse: 0.0154 - mape: 10.8174 - val_loss: 0.0093 - val_mse: 2.2820e-04 - val_rmse: 0.0151 - val_mape: 7.9378\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0109 - mse: 2.5948e-04 - rmse: 0.0161 - mape: 12.3047 - val_loss: 0.0105 - val_mse: 2.8056e-04 - val_rmse: 0.0168 - val_mape: 10.8096\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0114 - mse: 2.6426e-04 - rmse: 0.0163 - mape: 12.0073 - val_loss: 0.0110 - val_mse: 2.4285e-04 - val_rmse: 0.0156 - val_mape: 17.8777\n",
      "Epoch 167/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0115 - mse: 2.7683e-04 - rmse: 0.0166 - mape: 14.5946 - val_loss: 0.0122 - val_mse: 3.4039e-04 - val_rmse: 0.0184 - val_mape: 9.4831\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0109 - mse: 2.2258e-04 - rmse: 0.0149 - mape: 17.9618 - val_loss: 0.0113 - val_mse: 2.4545e-04 - val_rmse: 0.0157 - val_mape: 18.0219\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0100 - mse: 1.9788e-04 - rmse: 0.0141 - mape: 15.7175 - val_loss: 0.0109 - val_mse: 2.0744e-04 - val_rmse: 0.0144 - val_mape: 25.6989\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0105 - mse: 2.1580e-04 - rmse: 0.0147 - mape: 18.0747 - val_loss: 0.0121 - val_mse: 2.9790e-04 - val_rmse: 0.0173 - val_mape: 15.2909\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0104 - mse: 2.3855e-04 - rmse: 0.0154 - mape: 11.7658 - val_loss: 0.0094 - val_mse: 1.7311e-04 - val_rmse: 0.0132 - val_mape: 15.9451\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0110 - mse: 2.6590e-04 - rmse: 0.0163 - mape: 8.9766 - val_loss: 0.0131 - val_mse: 3.9351e-04 - val_rmse: 0.0198 - val_mape: 10.2943\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0106 - mse: 2.4194e-04 - rmse: 0.0156 - mape: 7.9188 - val_loss: 0.0131 - val_mse: 3.4687e-04 - val_rmse: 0.0186 - val_mape: 13.2888\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0109 - mse: 2.5703e-04 - rmse: 0.0160 - mape: 11.0931 - val_loss: 0.0118 - val_mse: 3.3691e-04 - val_rmse: 0.0184 - val_mape: 8.7656\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0101 - mse: 2.2159e-04 - rmse: 0.0149 - mape: 7.2710 - val_loss: 0.0098 - val_mse: 2.2596e-04 - val_rmse: 0.0150 - val_mape: 5.7976\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0094 - mse: 2.1926e-04 - rmse: 0.0148 - mape: 5.9806 - val_loss: 0.0096 - val_mse: 2.2617e-04 - val_rmse: 0.0150 - val_mape: 7.3777\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0098 - mse: 2.3305e-04 - rmse: 0.0153 - mape: 6.3789 - val_loss: 0.0099 - val_mse: 2.1968e-04 - val_rmse: 0.0148 - val_mape: 11.2405\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0103 - mse: 2.3059e-04 - rmse: 0.0152 - mape: 9.2290 - val_loss: 0.0108 - val_mse: 2.8408e-04 - val_rmse: 0.0169 - val_mape: 10.3387\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0098 - mse: 2.1088e-04 - rmse: 0.0145 - mape: 9.6792 - val_loss: 0.0096 - val_mse: 2.1110e-04 - val_rmse: 0.0145 - val_mape: 5.1660\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0102 - mse: 2.4111e-04 - rmse: 0.0155 - mape: 8.0001 - val_loss: 0.0082 - val_mse: 1.5555e-04 - val_rmse: 0.0125 - val_mape: 6.9671\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0094 - mse: 2.1573e-04 - rmse: 0.0147 - mape: 5.4906 - val_loss: 0.0100 - val_mse: 2.3212e-04 - val_rmse: 0.0152 - val_mape: 3.9129\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0096 - mse: 2.1021e-04 - rmse: 0.0145 - mape: 5.5332 - val_loss: 0.0137 - val_mse: 4.3322e-04 - val_rmse: 0.0208 - val_mape: 5.2965\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0113 - mse: 3.0095e-04 - rmse: 0.0173 - mape: 5.8097 - val_loss: 0.0112 - val_mse: 2.9964e-04 - val_rmse: 0.0173 - val_mape: 6.7616\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0106 - mse: 2.5762e-04 - rmse: 0.0161 - mape: 5.6690 - val_loss: 0.0094 - val_mse: 1.6711e-04 - val_rmse: 0.0129 - val_mape: 9.6776\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0103 - mse: 2.3596e-04 - rmse: 0.0154 - mape: 9.8072 - val_loss: 0.0094 - val_mse: 1.7748e-04 - val_rmse: 0.0133 - val_mape: 7.5734\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0102 - mse: 2.1557e-04 - rmse: 0.0147 - mape: 9.4592 - val_loss: 0.0088 - val_mse: 1.9714e-04 - val_rmse: 0.0140 - val_mape: 8.1778\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0104 - mse: 2.6408e-04 - rmse: 0.0163 - mape: 6.0081 - val_loss: 0.0105 - val_mse: 2.4770e-04 - val_rmse: 0.0157 - val_mape: 12.2080\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0098 - mse: 1.9528e-04 - rmse: 0.0140 - mape: 11.8980 - val_loss: 0.0105 - val_mse: 2.5553e-04 - val_rmse: 0.0160 - val_mape: 6.6846\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0111 - mse: 2.6574e-04 - rmse: 0.0163 - mape: 15.8897 - val_loss: 0.0090 - val_mse: 1.8382e-04 - val_rmse: 0.0136 - val_mape: 7.0365\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0095 - mse: 2.1586e-04 - rmse: 0.0147 - mape: 7.6930 - val_loss: 0.0086 - val_mse: 1.6757e-04 - val_rmse: 0.0129 - val_mape: 9.1137\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0093 - mse: 1.8696e-04 - rmse: 0.0137 - mape: 11.5992 - val_loss: 0.0097 - val_mse: 1.9574e-04 - val_rmse: 0.0140 - val_mape: 9.1392\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0099 - mse: 2.2251e-04 - rmse: 0.0149 - mape: 6.6418 - val_loss: 0.0090 - val_mse: 1.8952e-04 - val_rmse: 0.0138 - val_mape: 6.1078\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0085 - mse: 1.9470e-04 - rmse: 0.0140 - mape: 8.0221 - val_loss: 0.0083 - val_mse: 1.4923e-04 - val_rmse: 0.0122 - val_mape: 6.6024\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0093 - mse: 2.2512e-04 - rmse: 0.0150 - mape: 8.6346 - val_loss: 0.0090 - val_mse: 1.6305e-04 - val_rmse: 0.0128 - val_mape: 15.7956\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0090 - mse: 2.0261e-04 - rmse: 0.0142 - mape: 8.6435 - val_loss: 0.0080 - val_mse: 1.3977e-04 - val_rmse: 0.0118 - val_mape: 4.6327\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0102 - mse: 2.5606e-04 - rmse: 0.0160 - mape: 5.7765 - val_loss: 0.0098 - val_mse: 2.4581e-04 - val_rmse: 0.0157 - val_mape: 4.7110\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0093 - mse: 2.2716e-04 - rmse: 0.0151 - mape: 5.5370 - val_loss: 0.0082 - val_mse: 1.6143e-04 - val_rmse: 0.0127 - val_mape: 3.2439\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0094 - mse: 2.1931e-04 - rmse: 0.0148 - mape: 4.3938 - val_loss: 0.0096 - val_mse: 2.3264e-04 - val_rmse: 0.0153 - val_mape: 4.2263\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0094 - mse: 2.1299e-04 - rmse: 0.0146 - mape: 7.6834 - val_loss: 0.0072 - val_mse: 1.2677e-04 - val_rmse: 0.0113 - val_mape: 3.9372\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0098 - mse: 2.3505e-04 - rmse: 0.0153 - mape: 6.5948 - val_loss: 0.0117 - val_mse: 2.9574e-04 - val_rmse: 0.0172 - val_mape: 5.9052\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0124 - mse: 3.5153e-04 - rmse: 0.0187 - mape: 6.7876\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "neurons = 14\n",
    "model, scaler, loss, history, cl_train, cd_train, cl_test, cd_test = ANN_model(X, y, neurons ,activation, loss_func, epoch, batch_size, validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d6fd5f1-7053-42e8-9b64-af1a8ab57df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.012432246468961239,\n",
       " 0.0003515292191877961,\n",
       " 0.018749114125967026,\n",
       " 6.787629127502441]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a55382f5-10b5-475b-ada2-bd22e3b0aeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1891209267021865 7.506557679419609 3.786836620198061 9.788422733860717\n"
     ]
    }
   ],
   "source": [
    "print (cl_train, cd_train, cl_test, cd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e04f8842-6faf-44f3-a905-5c315a7f7636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Validation_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a55523a3-78a9-49a2-ac16-36127b06ca97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_file__14_mae.joblib']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib.dump(model, 'model__14_mae.joblib')\n",
    "# joblib.dump(scaler, 'scaler_file__14_mae.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9875c0-23f3-4348-86f4-395c86998587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
