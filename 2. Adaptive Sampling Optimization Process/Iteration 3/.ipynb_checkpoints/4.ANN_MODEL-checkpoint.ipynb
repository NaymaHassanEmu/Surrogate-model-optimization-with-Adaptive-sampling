{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fceaeeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import nan\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import joblib\n",
    "# %run 3.Xfoil_runner_extract_value.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "314ed73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>CL</th>\n",
       "      <th>CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>-0.0086</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>0.5294</td>\n",
       "      <td>0.00733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0045</td>\n",
       "      <td>-0.0035</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>-0.0060</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.6747</td>\n",
       "      <td>0.00947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.0093</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>-0.0113</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>-0.0093</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.4693</td>\n",
       "      <td>0.00959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0093</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0092</td>\n",
       "      <td>0.5034</td>\n",
       "      <td>0.00928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>-0.0039</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>-0.0087</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.00916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>-0.0032</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>-0.0114</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.6251</td>\n",
       "      <td>0.00798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>-0.0063</td>\n",
       "      <td>-0.0128</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>-0.0113</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.6383</td>\n",
       "      <td>0.00789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>-0.0070</td>\n",
       "      <td>-0.0109</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>-0.0120</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.6353</td>\n",
       "      <td>0.00795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>-0.0064</td>\n",
       "      <td>-0.0120</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>-0.0127</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.6356</td>\n",
       "      <td>0.00791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>-0.0117</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>-0.0115</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.6318</td>\n",
       "      <td>0.00793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1      x2      x3      x4      x5      x6      x7      x8      CL  \\\n",
       "0    0.0084  0.0104 -0.0033 -0.0033 -0.0086  0.0015 -0.0019 -0.0027  0.5294   \n",
       "1   -0.0045 -0.0035  0.0057  0.0062  0.0106 -0.0060  0.0101  0.0037  0.6747   \n",
       "2   -0.0093  0.0038 -0.0083 -0.0113  0.0030 -0.0028 -0.0093  0.0085  0.4693   \n",
       "3    0.0019 -0.0093  0.0067  0.0025 -0.0012  0.0077  0.0026 -0.0092  0.5034   \n",
       "4    0.0045  0.0017  0.0026  0.0050 -0.0039  0.0034 -0.0087  0.0105  0.6249   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "170  0.0110  0.0077 -0.0032 -0.0118  0.0111 -0.0114  0.0064  0.0104  0.6251   \n",
       "171  0.0115  0.0120 -0.0063 -0.0128  0.0070 -0.0113  0.0099  0.0118  0.6383   \n",
       "172  0.0125  0.0107 -0.0070 -0.0109  0.0083 -0.0120  0.0086  0.0113  0.6353   \n",
       "173  0.0118  0.0115 -0.0064 -0.0120  0.0076 -0.0127  0.0104  0.0110  0.6356   \n",
       "174  0.0107  0.0114 -0.0079 -0.0117  0.0066 -0.0115  0.0091  0.0125  0.6318   \n",
       "\n",
       "          CD  \n",
       "0    0.00733  \n",
       "1    0.00947  \n",
       "2    0.00959  \n",
       "3    0.00928  \n",
       "4    0.00916  \n",
       "..       ...  \n",
       "170  0.00798  \n",
       "171  0.00789  \n",
       "172  0.00795  \n",
       "173  0.00791  \n",
       "174  0.00793  \n",
       "\n",
       "[166 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('new_dataset.xlsx')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df.to_excel('dataset.xlsx')\n",
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "747243e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f00ee668",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8'] ]\n",
    "y = df[['CL', 'CD'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b69a06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>-0.0086</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0045</td>\n",
       "      <td>-0.0035</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>-0.0060</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.0093</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>-0.0113</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>-0.0093</td>\n",
       "      <td>0.0085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0093</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>-0.0039</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>-0.0087</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>-0.0032</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>-0.0114</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>-0.0063</td>\n",
       "      <td>-0.0128</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>-0.0113</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>-0.0070</td>\n",
       "      <td>-0.0109</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>-0.0120</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>-0.0064</td>\n",
       "      <td>-0.0120</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>-0.0127</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>-0.0117</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>-0.0115</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1      x2      x3      x4      x5      x6      x7      x8\n",
       "0    0.0084  0.0104 -0.0033 -0.0033 -0.0086  0.0015 -0.0019 -0.0027\n",
       "1   -0.0045 -0.0035  0.0057  0.0062  0.0106 -0.0060  0.0101  0.0037\n",
       "2   -0.0093  0.0038 -0.0083 -0.0113  0.0030 -0.0028 -0.0093  0.0085\n",
       "3    0.0019 -0.0093  0.0067  0.0025 -0.0012  0.0077  0.0026 -0.0092\n",
       "4    0.0045  0.0017  0.0026  0.0050 -0.0039  0.0034 -0.0087  0.0105\n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...\n",
       "170  0.0110  0.0077 -0.0032 -0.0118  0.0111 -0.0114  0.0064  0.0104\n",
       "171  0.0115  0.0120 -0.0063 -0.0128  0.0070 -0.0113  0.0099  0.0118\n",
       "172  0.0125  0.0107 -0.0070 -0.0109  0.0083 -0.0120  0.0086  0.0113\n",
       "173  0.0118  0.0115 -0.0064 -0.0120  0.0076 -0.0127  0.0104  0.0110\n",
       "174  0.0107  0.0114 -0.0079 -0.0117  0.0066 -0.0115  0.0091  0.0125\n",
       "\n",
       "[166 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61e845bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CL</th>\n",
       "      <th>CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5294</td>\n",
       "      <td>0.00733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6747</td>\n",
       "      <td>0.00947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4693</td>\n",
       "      <td>0.00959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5034</td>\n",
       "      <td>0.00928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.00916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.6251</td>\n",
       "      <td>0.00798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.6383</td>\n",
       "      <td>0.00789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.6353</td>\n",
       "      <td>0.00795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.6356</td>\n",
       "      <td>0.00791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.6318</td>\n",
       "      <td>0.00793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CL       CD\n",
       "0    0.5294  0.00733\n",
       "1    0.6747  0.00947\n",
       "2    0.4693  0.00959\n",
       "3    0.5034  0.00928\n",
       "4    0.6249  0.00916\n",
       "..      ...      ...\n",
       "170  0.6251  0.00798\n",
       "171  0.6383  0.00789\n",
       "172  0.6353  0.00795\n",
       "173  0.6356  0.00791\n",
       "174  0.6318  0.00793\n",
       "\n",
       "[166 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2bb1fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "628f7280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mean_absolute_percentage_error(y_true, y_pred):\n",
    "#     y_true = tf.where(tf.equal(y_true, 0.0), 1e-10, y_true)\n",
    "#     ape = tf.abs((y_true - y_pred) / y_true)*100\n",
    "#     ape = tf.where(tf.math.is_finite(ape), ape, 0.0)\n",
    "#     mape = tf.reduce_mean(ape)\n",
    "    \n",
    "#     return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c494d71-9b6f-42e9-b604-7750685321b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def root_mean_squared_error(y_true, y_pred):\n",
    "#     return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b69f480-f990-4239-bb0e-5842c7cdfaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_mape(X,y, model):\n",
    "    predictions = model.predict(X)\n",
    "    y = y = np.array(y)\n",
    "    absolute_errors = np.abs(predictions - y)\n",
    "    percentage_errors = (absolute_errors / np.abs(y)) * 100\n",
    "    mape_Cl = np.mean(percentage_errors[:, 0])  \n",
    "    mape_Cd = np.mean(percentage_errors[:, 1]) \n",
    "    return mape_Cl, mape_Cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "095fe53c-1c75-4a2f-8dce-693754010ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KFOLD_CROSS_VAL(X, y, n_fold, neurons ,activation, loss_func, epoch, batch_size):\n",
    "    kf = KFold(n_splits=n_fold, shuffle=True)\n",
    "    num_rows = 0\n",
    "    num_cols = 4\n",
    "    loss_score = np.empty((num_rows, num_cols))\n",
    "    \n",
    "    for train_index, val_index in kf.split(X, y):\n",
    "        X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "        scaler = StandardScaler()\n",
    "        X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "        X_val_fold = scaler.transform(X_val_fold)\n",
    "        \n",
    "        from tensorflow.keras.optimizers import Adam\n",
    "        optimizer = Adam(learning_rate=0.01)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(neurons, input_dim=8, activation=activation, kernel_regularizer = regularizers.l2(0.01)))\n",
    "        model.add(Dense(2, activation='linear'))\n",
    "        model.compile(loss=loss_func, optimizer=optimizer, metrics=['mse',tf.keras.metrics.RootMeanSquaredError(name='rmse'),'mape'])\n",
    "        model.fit(X_train_fold, y_train_fold, epochs= epoch, batch_size= batch_size)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        loss = model.evaluate(X_val_fold, y_val_fold)\n",
    "        loss_score = np.vstack([loss_score, np.array(loss)])\n",
    "    \n",
    "    # Calculate average accuracy and other metrics if needed\n",
    "    average_loss = np.mean(loss_score, axis=0)\n",
    "    return loss_score, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb68ec90-4b38-418f-bbe3-64adf3c50278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_model(X, y, neurons ,activation, loss_func, epoch, batch_size, validation_split):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    optimizer = Adam(learning_rate=0.01)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=8, activation=activation, kernel_regularizer = regularizers.l2(0.01)))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    model.compile(loss= loss_func, optimizer=optimizer, metrics=['mse',tf.keras.metrics.RootMeanSquaredError(name='rmse'),'mape'])\n",
    "    history = model.fit(X_train, y_train, epochs=epoch, batch_size=batch_size, validation_split=validation_split)\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "\n",
    "    cl_train, cd_train = cal_mape(X_train,y_train, model)\n",
    "    cl_test, cd_test = cal_mape(X_test,y_test, model)\n",
    "    return model, scaler, loss, history, cl_train, cd_train, cl_test, cd_test\n",
    "\n",
    "def DNN_model(X, y, H1_neurons , H2_neurons ,activation, loss_func, epoch, batch_size, validation_split):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    optimizer = Adam(learning_rate=0.01)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(H1_neurons, input_dim=8, activation=activation, kernel_regularizer = regularizers.l2(0.01)))\n",
    "    model.add(Dense(H2_neurons, activation=activation))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    model.compile(loss= loss_func, optimizer=optimizer, metrics=['mse',tf.keras.metrics.RootMeanSquaredError(name='rmse'),'mape'])\n",
    "    history = model.fit(X_train, y_train, epochs=epoch, batch_size=batch_size, validation_split=validation_split)\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "\n",
    "    cl_train, cd_train = cal_mape(X_train,y_train, model)\n",
    "    cl_test, cd_test = cal_mape(X_test,y_test, model)\n",
    "    return model, scaler, loss, history, cl_train, cd_train, cl_test, cd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14463f9e-d08f-4ff2-98dd-fa3c33a08351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Validation_curves(history):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29a4df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "# neurons_list = [4,6,8,10,12,14,16]\n",
    "activation = 'tanh'\n",
    "loss_func = 'mean_absolute_error'\n",
    "epoch = 200\n",
    "batch_size = 16\n",
    "validation_split = 0.2\n",
    "mae= []\n",
    "mse = []\n",
    "RMSE = []\n",
    "mape = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b078dc03-e565-4d35-a43a-3531628022ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 1s 49ms/step - loss: 0.8270 - mse: 0.8893 - rmse: 0.9431 - mape: 3477.4580 - val_loss: 0.6692 - val_mse: 0.5026 - val_rmse: 0.7089 - val_mape: 2861.7812\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4706 - mse: 0.2257 - rmse: 0.4751 - mape: 2018.9237 - val_loss: 0.4153 - val_mse: 0.1686 - val_rmse: 0.4106 - val_mape: 2146.5454\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3005 - mse: 0.0741 - rmse: 0.2723 - mape: 1191.6565 - val_loss: 0.2844 - val_mse: 0.0576 - val_rmse: 0.2399 - val_mape: 1104.5382\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2349 - mse: 0.0392 - rmse: 0.1980 - mape: 699.9926 - val_loss: 0.2511 - val_mse: 0.0460 - val_rmse: 0.2144 - val_mape: 586.2097\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2069 - mse: 0.0268 - rmse: 0.1637 - mape: 443.1659 - val_loss: 0.1964 - val_mse: 0.0248 - val_rmse: 0.1576 - val_mape: 315.3650\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1677 - mse: 0.0133 - rmse: 0.1152 - mape: 347.3283 - val_loss: 0.1584 - val_mse: 0.0115 - val_rmse: 0.1071 - val_mape: 376.5446\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1470 - mse: 0.0099 - rmse: 0.0997 - mape: 329.3130 - val_loss: 0.1379 - val_mse: 0.0091 - val_rmse: 0.0955 - val_mape: 245.0008\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1257 - mse: 0.0067 - rmse: 0.0820 - mape: 219.9513 - val_loss: 0.1121 - val_mse: 0.0065 - val_rmse: 0.0806 - val_mape: 158.3314\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1163 - mse: 0.0053 - rmse: 0.0725 - mape: 212.8559 - val_loss: 0.1094 - val_mse: 0.0053 - val_rmse: 0.0728 - val_mape: 159.5469\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1049 - mse: 0.0043 - rmse: 0.0656 - mape: 178.8021 - val_loss: 0.1090 - val_mse: 0.0060 - val_rmse: 0.0777 - val_mape: 178.1612\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0949 - mse: 0.0037 - rmse: 0.0605 - mape: 165.0845 - val_loss: 0.0935 - val_mse: 0.0038 - val_rmse: 0.0620 - val_mape: 154.5685\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0878 - mse: 0.0028 - rmse: 0.0533 - mape: 146.9651 - val_loss: 0.0948 - val_mse: 0.0049 - val_rmse: 0.0699 - val_mape: 157.0362\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0970 - mse: 0.0050 - rmse: 0.0708 - mape: 172.3545 - val_loss: 0.0871 - val_mse: 0.0039 - val_rmse: 0.0621 - val_mape: 122.0549\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0800 - mse: 0.0025 - rmse: 0.0499 - mape: 158.1714 - val_loss: 0.0890 - val_mse: 0.0045 - val_rmse: 0.0672 - val_mape: 202.4384\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0749 - mse: 0.0022 - rmse: 0.0472 - mape: 147.4642 - val_loss: 0.0707 - val_mse: 0.0024 - val_rmse: 0.0494 - val_mape: 97.9802\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0654 - mse: 0.0015 - rmse: 0.0388 - mape: 113.3478 - val_loss: 0.0680 - val_mse: 0.0022 - val_rmse: 0.0464 - val_mape: 79.3534\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0633 - mse: 0.0015 - rmse: 0.0392 - mape: 107.9910 - val_loss: 0.0758 - val_mse: 0.0033 - val_rmse: 0.0578 - val_mape: 117.6327\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0634 - mse: 0.0020 - rmse: 0.0446 - mape: 105.8285 - val_loss: 0.0570 - val_mse: 0.0014 - val_rmse: 0.0374 - val_mape: 97.3234\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0600 - mse: 0.0017 - rmse: 0.0409 - mape: 104.0050 - val_loss: 0.0570 - val_mse: 0.0015 - val_rmse: 0.0382 - val_mape: 85.5963\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0563 - mse: 0.0016 - rmse: 0.0402 - mape: 100.0643 - val_loss: 0.0543 - val_mse: 0.0016 - val_rmse: 0.0400 - val_mape: 67.7822\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0476 - mse: 8.5336e-04 - rmse: 0.0292 - mape: 71.2434 - val_loss: 0.0484 - val_mse: 0.0014 - val_rmse: 0.0378 - val_mape: 74.7622\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0485 - mse: 0.0010 - rmse: 0.0320 - mape: 80.8272 - val_loss: 0.0518 - val_mse: 0.0017 - val_rmse: 0.0409 - val_mape: 72.3517\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0491 - mse: 0.0014 - rmse: 0.0378 - mape: 79.9036 - val_loss: 0.0487 - val_mse: 0.0014 - val_rmse: 0.0370 - val_mape: 73.4707\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0437 - mse: 0.0010 - rmse: 0.0321 - mape: 65.3258 - val_loss: 0.0445 - val_mse: 0.0015 - val_rmse: 0.0386 - val_mape: 42.2922\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0414 - mse: 9.1518e-04 - rmse: 0.0303 - mape: 56.5724 - val_loss: 0.0419 - val_mse: 0.0010 - val_rmse: 0.0319 - val_mape: 55.3819\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0367 - mse: 6.3726e-04 - rmse: 0.0252 - mape: 46.4224 - val_loss: 0.0413 - val_mse: 0.0013 - val_rmse: 0.0354 - val_mape: 42.5286\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0359 - mse: 6.5075e-04 - rmse: 0.0255 - mape: 50.4935 - val_loss: 0.0372 - val_mse: 9.3882e-04 - val_rmse: 0.0306 - val_mape: 42.3540\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0353 - mse: 6.7936e-04 - rmse: 0.0261 - mape: 51.9840 - val_loss: 0.0416 - val_mse: 0.0014 - val_rmse: 0.0379 - val_mape: 61.3702\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0340 - mse: 6.0384e-04 - rmse: 0.0246 - mape: 54.5445 - val_loss: 0.0334 - val_mse: 7.2386e-04 - val_rmse: 0.0269 - val_mape: 40.7849\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0324 - mse: 6.3326e-04 - rmse: 0.0252 - mape: 51.8766 - val_loss: 0.0373 - val_mse: 0.0013 - val_rmse: 0.0356 - val_mape: 40.0103\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0314 - mse: 6.4497e-04 - rmse: 0.0254 - mape: 38.4553 - val_loss: 0.0321 - val_mse: 7.0890e-04 - val_rmse: 0.0266 - val_mape: 40.6539\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0276 - mse: 4.4789e-04 - rmse: 0.0212 - mape: 36.4062 - val_loss: 0.0285 - val_mse: 8.1178e-04 - val_rmse: 0.0285 - val_mape: 25.8256\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0289 - mse: 5.9738e-04 - rmse: 0.0244 - mape: 33.7670 - val_loss: 0.0298 - val_mse: 5.3756e-04 - val_rmse: 0.0232 - val_mape: 61.5314\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0326 - mse: 8.3101e-04 - rmse: 0.0288 - mape: 66.6226 - val_loss: 0.0315 - val_mse: 9.8560e-04 - val_rmse: 0.0314 - val_mape: 28.6418\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0287 - mse: 6.2569e-04 - rmse: 0.0250 - mape: 45.3130 - val_loss: 0.0259 - val_mse: 4.7108e-04 - val_rmse: 0.0217 - val_mape: 45.2026\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0255 - mse: 4.2433e-04 - rmse: 0.0206 - mape: 50.6784 - val_loss: 0.0232 - val_mse: 3.8643e-04 - val_rmse: 0.0197 - val_mape: 38.4339\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0271 - mse: 5.6460e-04 - rmse: 0.0238 - mape: 51.7084 - val_loss: 0.0290 - val_mse: 7.6843e-04 - val_rmse: 0.0277 - val_mape: 43.0435\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0290 - mse: 8.2892e-04 - rmse: 0.0288 - mape: 45.1233 - val_loss: 0.0239 - val_mse: 5.0160e-04 - val_rmse: 0.0224 - val_mape: 47.1085\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0269 - mse: 6.7779e-04 - rmse: 0.0260 - mape: 45.1888 - val_loss: 0.0253 - val_mse: 5.5892e-04 - val_rmse: 0.0236 - val_mape: 47.3223\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0229 - mse: 3.8948e-04 - rmse: 0.0197 - mape: 47.7496 - val_loss: 0.0251 - val_mse: 6.9364e-04 - val_rmse: 0.0263 - val_mape: 37.2646\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0228 - mse: 5.4114e-04 - rmse: 0.0233 - mape: 35.8157 - val_loss: 0.0241 - val_mse: 4.8628e-04 - val_rmse: 0.0221 - val_mape: 41.0378\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0227 - mse: 5.0630e-04 - rmse: 0.0225 - mape: 35.4546 - val_loss: 0.0274 - val_mse: 7.8700e-04 - val_rmse: 0.0281 - val_mape: 47.7755\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0214 - mse: 4.4600e-04 - rmse: 0.0211 - mape: 35.7369 - val_loss: 0.0231 - val_mse: 6.4315e-04 - val_rmse: 0.0254 - val_mape: 33.7078\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0225 - mse: 5.5285e-04 - rmse: 0.0235 - mape: 35.5405 - val_loss: 0.0225 - val_mse: 5.2106e-04 - val_rmse: 0.0228 - val_mape: 38.3501\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0204 - mse: 4.3660e-04 - rmse: 0.0209 - mape: 27.7395 - val_loss: 0.0225 - val_mse: 5.8768e-04 - val_rmse: 0.0242 - val_mape: 30.5133\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0210 - mse: 5.0788e-04 - rmse: 0.0225 - mape: 26.0165 - val_loss: 0.0209 - val_mse: 5.7680e-04 - val_rmse: 0.0240 - val_mape: 19.4484\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0226 - mse: 7.3252e-04 - rmse: 0.0271 - mape: 29.3265 - val_loss: 0.0194 - val_mse: 4.3018e-04 - val_rmse: 0.0207 - val_mape: 27.3314\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0211 - mse: 5.3922e-04 - rmse: 0.0232 - mape: 38.4221 - val_loss: 0.0214 - val_mse: 5.7070e-04 - val_rmse: 0.0239 - val_mape: 39.0099\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0236 - mse: 6.5549e-04 - rmse: 0.0256 - mape: 54.4802 - val_loss: 0.0238 - val_mse: 8.2780e-04 - val_rmse: 0.0288 - val_mape: 35.0995\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0224 - mse: 6.0832e-04 - rmse: 0.0247 - mape: 49.5507 - val_loss: 0.0244 - val_mse: 7.8340e-04 - val_rmse: 0.0280 - val_mape: 46.0534\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0230 - mse: 6.9928e-04 - rmse: 0.0264 - mape: 44.2668 - val_loss: 0.0220 - val_mse: 7.6523e-04 - val_rmse: 0.0277 - val_mape: 42.3873\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0223 - mse: 7.2366e-04 - rmse: 0.0269 - mape: 32.8807 - val_loss: 0.0208 - val_mse: 4.4489e-04 - val_rmse: 0.0211 - val_mape: 46.4156\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0194 - mse: 5.1629e-04 - rmse: 0.0227 - mape: 41.5151 - val_loss: 0.0178 - val_mse: 4.0515e-04 - val_rmse: 0.0201 - val_mape: 31.6993\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0187 - mse: 4.4574e-04 - rmse: 0.0211 - mape: 37.7081 - val_loss: 0.0202 - val_mse: 7.4809e-04 - val_rmse: 0.0274 - val_mape: 40.8238\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0202 - mse: 5.9028e-04 - rmse: 0.0243 - mape: 42.7029 - val_loss: 0.0143 - val_mse: 2.5628e-04 - val_rmse: 0.0160 - val_mape: 21.0473\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0180 - mse: 5.4989e-04 - rmse: 0.0234 - mape: 24.1062 - val_loss: 0.0200 - val_mse: 6.8403e-04 - val_rmse: 0.0262 - val_mape: 19.7641\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0201 - mse: 6.3954e-04 - rmse: 0.0253 - mape: 24.5516 - val_loss: 0.0166 - val_mse: 3.7503e-04 - val_rmse: 0.0194 - val_mape: 28.0743\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0160 - mse: 3.6636e-04 - rmse: 0.0191 - mape: 21.8457 - val_loss: 0.0141 - val_mse: 3.0016e-04 - val_rmse: 0.0173 - val_mape: 22.6852\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0162 - mse: 3.8882e-04 - rmse: 0.0197 - mape: 25.4525 - val_loss: 0.0137 - val_mse: 3.7815e-04 - val_rmse: 0.0194 - val_mape: 14.0156\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0149 - mse: 3.2225e-04 - rmse: 0.0180 - mape: 25.1164 - val_loss: 0.0145 - val_mse: 3.4533e-04 - val_rmse: 0.0186 - val_mape: 14.3847\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0163 - mse: 4.3204e-04 - rmse: 0.0208 - mape: 22.0564 - val_loss: 0.0141 - val_mse: 2.6805e-04 - val_rmse: 0.0164 - val_mape: 32.3238\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0177 - mse: 4.6715e-04 - rmse: 0.0216 - mape: 24.1485 - val_loss: 0.0143 - val_mse: 3.3566e-04 - val_rmse: 0.0183 - val_mape: 34.2758\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0168 - mse: 4.4438e-04 - rmse: 0.0211 - mape: 23.4073 - val_loss: 0.0184 - val_mse: 5.0457e-04 - val_rmse: 0.0225 - val_mape: 44.1376\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0193 - mse: 5.4209e-04 - rmse: 0.0233 - mape: 36.5104 - val_loss: 0.0170 - val_mse: 4.7757e-04 - val_rmse: 0.0219 - val_mape: 32.5071\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0210 - mse: 8.2618e-04 - rmse: 0.0287 - mape: 37.3481 - val_loss: 0.0231 - val_mse: 9.0698e-04 - val_rmse: 0.0301 - val_mape: 26.1519\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0209 - mse: 7.7807e-04 - rmse: 0.0279 - mape: 34.9365 - val_loss: 0.0204 - val_mse: 6.9988e-04 - val_rmse: 0.0265 - val_mape: 49.3148\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0210 - mse: 7.2724e-04 - rmse: 0.0270 - mape: 40.9103 - val_loss: 0.0206 - val_mse: 7.6252e-04 - val_rmse: 0.0276 - val_mape: 30.5233\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0185 - mse: 6.6899e-04 - rmse: 0.0259 - mape: 28.3284 - val_loss: 0.0195 - val_mse: 9.5189e-04 - val_rmse: 0.0309 - val_mape: 18.1278\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0165 - mse: 5.1197e-04 - rmse: 0.0226 - mape: 19.9615 - val_loss: 0.0158 - val_mse: 5.8688e-04 - val_rmse: 0.0242 - val_mape: 16.0009\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0163 - mse: 5.0251e-04 - rmse: 0.0224 - mape: 23.2304 - val_loss: 0.0123 - val_mse: 2.8878e-04 - val_rmse: 0.0170 - val_mape: 19.4262\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0144 - mse: 3.6391e-04 - rmse: 0.0191 - mape: 20.9253 - val_loss: 0.0121 - val_mse: 2.4566e-04 - val_rmse: 0.0157 - val_mape: 22.5858\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0140 - mse: 3.7272e-04 - rmse: 0.0193 - mape: 17.2569 - val_loss: 0.0138 - val_mse: 3.1036e-04 - val_rmse: 0.0176 - val_mape: 19.6522\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0149 - mse: 4.4103e-04 - rmse: 0.0210 - mape: 17.4734 - val_loss: 0.0117 - val_mse: 2.5313e-04 - val_rmse: 0.0159 - val_mape: 11.8232\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0133 - mse: 3.6198e-04 - rmse: 0.0190 - mape: 15.8817 - val_loss: 0.0150 - val_mse: 3.7757e-04 - val_rmse: 0.0194 - val_mape: 17.9877\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0124 - mse: 3.0920e-04 - rmse: 0.0176 - mape: 14.7321 - val_loss: 0.0137 - val_mse: 3.3118e-04 - val_rmse: 0.0182 - val_mape: 19.6049\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0151 - mse: 4.6941e-04 - rmse: 0.0217 - mape: 22.9974 - val_loss: 0.0118 - val_mse: 2.5716e-04 - val_rmse: 0.0160 - val_mape: 20.6969\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0158 - mse: 4.5989e-04 - rmse: 0.0214 - mape: 21.9772 - val_loss: 0.0105 - val_mse: 2.4061e-04 - val_rmse: 0.0155 - val_mape: 8.7580\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0166 - mse: 6.3935e-04 - rmse: 0.0253 - mape: 14.8899 - val_loss: 0.0113 - val_mse: 2.4575e-04 - val_rmse: 0.0157 - val_mape: 10.2580\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0169 - mse: 6.6374e-04 - rmse: 0.0258 - mape: 16.8447 - val_loss: 0.0136 - val_mse: 3.9046e-04 - val_rmse: 0.0198 - val_mape: 19.8075\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0142 - mse: 4.1406e-04 - rmse: 0.0203 - mape: 14.7804 - val_loss: 0.0157 - val_mse: 4.8356e-04 - val_rmse: 0.0220 - val_mape: 13.5160\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0127 - mse: 3.4842e-04 - rmse: 0.0187 - mape: 9.4243 - val_loss: 0.0127 - val_mse: 3.3336e-04 - val_rmse: 0.0183 - val_mape: 11.4716\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0141 - mse: 3.8967e-04 - rmse: 0.0197 - mape: 12.0593 - val_loss: 0.0112 - val_mse: 2.3749e-04 - val_rmse: 0.0154 - val_mape: 15.7236\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0122 - mse: 2.9428e-04 - rmse: 0.0172 - mape: 18.5814 - val_loss: 0.0097 - val_mse: 2.1851e-04 - val_rmse: 0.0148 - val_mape: 12.0964\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0113 - mse: 2.8496e-04 - rmse: 0.0169 - mape: 11.0119 - val_loss: 0.0134 - val_mse: 3.5372e-04 - val_rmse: 0.0188 - val_mape: 13.3154\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0122 - mse: 3.2891e-04 - rmse: 0.0181 - mape: 11.2069 - val_loss: 0.0114 - val_mse: 3.1257e-04 - val_rmse: 0.0177 - val_mape: 5.8268\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0134 - mse: 4.2261e-04 - rmse: 0.0206 - mape: 12.8069 - val_loss: 0.0102 - val_mse: 2.5608e-04 - val_rmse: 0.0160 - val_mape: 8.3753\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0133 - mse: 3.9841e-04 - rmse: 0.0200 - mape: 11.8713 - val_loss: 0.0109 - val_mse: 2.4549e-04 - val_rmse: 0.0157 - val_mape: 5.0725\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0131 - mse: 3.8782e-04 - rmse: 0.0197 - mape: 8.4211 - val_loss: 0.0134 - val_mse: 4.5262e-04 - val_rmse: 0.0213 - val_mape: 11.4718\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0139 - mse: 4.0819e-04 - rmse: 0.0202 - mape: 15.3155 - val_loss: 0.0122 - val_mse: 2.7702e-04 - val_rmse: 0.0166 - val_mape: 28.8425\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0146 - mse: 3.8951e-04 - rmse: 0.0197 - mape: 27.9569 - val_loss: 0.0120 - val_mse: 2.1864e-04 - val_rmse: 0.0148 - val_mape: 35.9979\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0130 - mse: 3.1914e-04 - rmse: 0.0179 - mape: 25.4296 - val_loss: 0.0154 - val_mse: 4.0314e-04 - val_rmse: 0.0201 - val_mape: 30.4688\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0146 - mse: 4.2741e-04 - rmse: 0.0207 - mape: 25.6978 - val_loss: 0.0121 - val_mse: 3.1144e-04 - val_rmse: 0.0176 - val_mape: 20.2085\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0154 - mse: 4.4188e-04 - rmse: 0.0210 - mape: 23.8108 - val_loss: 0.0124 - val_mse: 3.9616e-04 - val_rmse: 0.0199 - val_mape: 17.2898\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0120 - mse: 2.6521e-04 - rmse: 0.0163 - mape: 19.4833 - val_loss: 0.0097 - val_mse: 1.9034e-04 - val_rmse: 0.0138 - val_mape: 16.1117\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0147 - mse: 4.3775e-04 - rmse: 0.0209 - mape: 18.0250 - val_loss: 0.0136 - val_mse: 3.6204e-04 - val_rmse: 0.0190 - val_mape: 12.2042\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0137 - mse: 3.9555e-04 - rmse: 0.0199 - mape: 11.5564 - val_loss: 0.0109 - val_mse: 2.2922e-04 - val_rmse: 0.0151 - val_mape: 13.2191\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0123 - mse: 3.3277e-04 - rmse: 0.0182 - mape: 16.1107 - val_loss: 0.0133 - val_mse: 4.6358e-04 - val_rmse: 0.0215 - val_mape: 9.3588\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0129 - mse: 3.2733e-04 - rmse: 0.0181 - mape: 16.8390 - val_loss: 0.0087 - val_mse: 1.8639e-04 - val_rmse: 0.0137 - val_mape: 11.0192\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0122 - mse: 3.4892e-04 - rmse: 0.0187 - mape: 15.6727 - val_loss: 0.0135 - val_mse: 4.2528e-04 - val_rmse: 0.0206 - val_mape: 11.8014\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0109 - mse: 2.6482e-04 - rmse: 0.0163 - mape: 10.9686 - val_loss: 0.0077 - val_mse: 1.4670e-04 - val_rmse: 0.0121 - val_mape: 4.1459\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0114 - mse: 3.0061e-04 - rmse: 0.0173 - mape: 8.0461 - val_loss: 0.0086 - val_mse: 1.8045e-04 - val_rmse: 0.0134 - val_mape: 4.1754\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0110 - mse: 2.9633e-04 - rmse: 0.0172 - mape: 6.7871 - val_loss: 0.0113 - val_mse: 3.0091e-04 - val_rmse: 0.0173 - val_mape: 13.5534\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0116 - mse: 3.0658e-04 - rmse: 0.0175 - mape: 10.4492 - val_loss: 0.0096 - val_mse: 1.8647e-04 - val_rmse: 0.0137 - val_mape: 13.2041\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0110 - mse: 2.8622e-04 - rmse: 0.0169 - mape: 12.7309 - val_loss: 0.0114 - val_mse: 2.6385e-04 - val_rmse: 0.0162 - val_mape: 18.7350\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0134 - mse: 4.1600e-04 - rmse: 0.0204 - mape: 12.4413 - val_loss: 0.0102 - val_mse: 2.6966e-04 - val_rmse: 0.0164 - val_mape: 8.8040\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0135 - mse: 4.9280e-04 - rmse: 0.0222 - mape: 13.5453 - val_loss: 0.0134 - val_mse: 3.4013e-04 - val_rmse: 0.0184 - val_mape: 11.1438\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0132 - mse: 3.2483e-04 - rmse: 0.0180 - mape: 23.5021 - val_loss: 0.0158 - val_mse: 5.4562e-04 - val_rmse: 0.0234 - val_mape: 11.5364\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0120 - mse: 3.2868e-04 - rmse: 0.0181 - mape: 18.5970 - val_loss: 0.0111 - val_mse: 1.9347e-04 - val_rmse: 0.0139 - val_mape: 34.4412\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0119 - mse: 2.5684e-04 - rmse: 0.0160 - mape: 29.8758 - val_loss: 0.0092 - val_mse: 1.5829e-04 - val_rmse: 0.0126 - val_mape: 18.7955\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0112 - mse: 2.5142e-04 - rmse: 0.0159 - mape: 19.0747 - val_loss: 0.0106 - val_mse: 2.1258e-04 - val_rmse: 0.0146 - val_mape: 25.2175\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0102 - mse: 2.1892e-04 - rmse: 0.0148 - mape: 18.8633 - val_loss: 0.0088 - val_mse: 1.9472e-04 - val_rmse: 0.0140 - val_mape: 7.1905\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0111 - mse: 2.7920e-04 - rmse: 0.0167 - mape: 12.9441 - val_loss: 0.0093 - val_mse: 2.0704e-04 - val_rmse: 0.0144 - val_mape: 7.5355\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0100 - mse: 2.0996e-04 - rmse: 0.0145 - mape: 14.0796 - val_loss: 0.0112 - val_mse: 2.7180e-04 - val_rmse: 0.0165 - val_mape: 20.0276\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0111 - mse: 2.7241e-04 - rmse: 0.0165 - mape: 13.1737 - val_loss: 0.0100 - val_mse: 2.0442e-04 - val_rmse: 0.0143 - val_mape: 9.2681\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0113 - mse: 2.4878e-04 - rmse: 0.0158 - mape: 14.6488 - val_loss: 0.0101 - val_mse: 1.7982e-04 - val_rmse: 0.0134 - val_mape: 21.9783\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0111 - mse: 2.3799e-04 - rmse: 0.0154 - mape: 18.7001 - val_loss: 0.0107 - val_mse: 2.3524e-04 - val_rmse: 0.0153 - val_mape: 13.0741\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0111 - mse: 2.6909e-04 - rmse: 0.0164 - mape: 11.5577 - val_loss: 0.0098 - val_mse: 1.9806e-04 - val_rmse: 0.0141 - val_mape: 10.8005\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0118 - mse: 2.9210e-04 - rmse: 0.0171 - mape: 18.1829 - val_loss: 0.0138 - val_mse: 3.3221e-04 - val_rmse: 0.0182 - val_mape: 31.1893\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0121 - mse: 2.7208e-04 - rmse: 0.0165 - mape: 25.8429 - val_loss: 0.0116 - val_mse: 2.2883e-04 - val_rmse: 0.0151 - val_mape: 31.7044\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0123 - mse: 2.8944e-04 - rmse: 0.0170 - mape: 23.8190 - val_loss: 0.0099 - val_mse: 1.5051e-04 - val_rmse: 0.0123 - val_mape: 24.2514\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0131 - mse: 3.5622e-04 - rmse: 0.0189 - mape: 21.0590 - val_loss: 0.0103 - val_mse: 3.3830e-04 - val_rmse: 0.0184 - val_mape: 12.1098\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0115 - mse: 2.9276e-04 - rmse: 0.0171 - mape: 10.5597 - val_loss: 0.0087 - val_mse: 2.0094e-04 - val_rmse: 0.0142 - val_mape: 4.7202\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0108 - mse: 2.7907e-04 - rmse: 0.0167 - mape: 6.8162 - val_loss: 0.0085 - val_mse: 1.3574e-04 - val_rmse: 0.0117 - val_mape: 3.9051\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0104 - mse: 2.4224e-04 - rmse: 0.0156 - mape: 7.8441 - val_loss: 0.0110 - val_mse: 2.5182e-04 - val_rmse: 0.0159 - val_mape: 12.3111\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0108 - mse: 2.4332e-04 - rmse: 0.0156 - mape: 14.6061 - val_loss: 0.0097 - val_mse: 2.0955e-04 - val_rmse: 0.0145 - val_mape: 9.7718\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0101 - mse: 2.3057e-04 - rmse: 0.0152 - mape: 13.1898 - val_loss: 0.0096 - val_mse: 1.8961e-04 - val_rmse: 0.0138 - val_mape: 21.6428\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0106 - mse: 2.0634e-04 - rmse: 0.0144 - mape: 19.1547 - val_loss: 0.0102 - val_mse: 1.6510e-04 - val_rmse: 0.0128 - val_mape: 22.2170\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0109 - mse: 2.2158e-04 - rmse: 0.0149 - mape: 18.5007 - val_loss: 0.0121 - val_mse: 2.4285e-04 - val_rmse: 0.0156 - val_mape: 28.8648\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0129 - mse: 2.9402e-04 - rmse: 0.0171 - mape: 27.1737 - val_loss: 0.0106 - val_mse: 1.8187e-04 - val_rmse: 0.0135 - val_mape: 24.8105\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0120 - mse: 2.9123e-04 - rmse: 0.0171 - mape: 20.0573 - val_loss: 0.0111 - val_mse: 2.3993e-04 - val_rmse: 0.0155 - val_mape: 19.0310\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0119 - mse: 3.1082e-04 - rmse: 0.0176 - mape: 14.4119 - val_loss: 0.0103 - val_mse: 2.4849e-04 - val_rmse: 0.0158 - val_mape: 9.9262\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0114 - mse: 3.0374e-04 - rmse: 0.0174 - mape: 9.2239 - val_loss: 0.0086 - val_mse: 1.3517e-04 - val_rmse: 0.0116 - val_mape: 9.9873\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0096 - mse: 2.0124e-04 - rmse: 0.0142 - mape: 10.4751 - val_loss: 0.0112 - val_mse: 3.2512e-04 - val_rmse: 0.0180 - val_mape: 6.8647\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0113 - mse: 3.0299e-04 - rmse: 0.0174 - mape: 7.1803 - val_loss: 0.0118 - val_mse: 3.2876e-04 - val_rmse: 0.0181 - val_mape: 6.5903\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0128 - mse: 3.8674e-04 - rmse: 0.0197 - mape: 12.3442 - val_loss: 0.0118 - val_mse: 2.6866e-04 - val_rmse: 0.0164 - val_mape: 8.0367\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0125 - mse: 3.4274e-04 - rmse: 0.0185 - mape: 13.7906 - val_loss: 0.0112 - val_mse: 1.7738e-04 - val_rmse: 0.0133 - val_mape: 25.6328\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0120 - mse: 2.7889e-04 - rmse: 0.0167 - mape: 19.4695 - val_loss: 0.0096 - val_mse: 2.7048e-04 - val_rmse: 0.0164 - val_mape: 8.1852\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0094 - mse: 2.2568e-04 - rmse: 0.0150 - mape: 10.0368 - val_loss: 0.0096 - val_mse: 2.3434e-04 - val_rmse: 0.0153 - val_mape: 8.4586\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0105 - mse: 2.4299e-04 - rmse: 0.0156 - mape: 8.1318 - val_loss: 0.0087 - val_mse: 1.3753e-04 - val_rmse: 0.0117 - val_mape: 9.9923\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0102 - mse: 2.4228e-04 - rmse: 0.0156 - mape: 10.0071 - val_loss: 0.0087 - val_mse: 1.7201e-04 - val_rmse: 0.0131 - val_mape: 7.2269\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0103 - mse: 2.1922e-04 - rmse: 0.0148 - mape: 13.7324 - val_loss: 0.0089 - val_mse: 1.8513e-04 - val_rmse: 0.0136 - val_mape: 9.1033\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0100 - mse: 2.1581e-04 - rmse: 0.0147 - mape: 13.6051 - val_loss: 0.0122 - val_mse: 3.3689e-04 - val_rmse: 0.0184 - val_mape: 15.6105\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0121 - mse: 2.9621e-04 - rmse: 0.0172 - mape: 19.1093 - val_loss: 0.0111 - val_mse: 1.9343e-04 - val_rmse: 0.0139 - val_mape: 33.1930\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0127 - mse: 2.7708e-04 - rmse: 0.0166 - mape: 30.8283 - val_loss: 0.0121 - val_mse: 2.7382e-04 - val_rmse: 0.0165 - val_mape: 32.7764\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0127 - mse: 2.8503e-04 - rmse: 0.0169 - mape: 28.4507 - val_loss: 0.0101 - val_mse: 1.7111e-04 - val_rmse: 0.0131 - val_mape: 25.9999\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0128 - mse: 3.0744e-04 - rmse: 0.0175 - mape: 25.3579 - val_loss: 0.0099 - val_mse: 1.8243e-04 - val_rmse: 0.0135 - val_mape: 17.8624\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0117 - mse: 2.7414e-04 - rmse: 0.0166 - mape: 20.1987 - val_loss: 0.0108 - val_mse: 2.2325e-04 - val_rmse: 0.0149 - val_mape: 17.7300\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0113 - mse: 2.4112e-04 - rmse: 0.0155 - mape: 17.1373 - val_loss: 0.0090 - val_mse: 2.0783e-04 - val_rmse: 0.0144 - val_mape: 6.5756\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0133 - mse: 4.1383e-04 - rmse: 0.0203 - mape: 8.2745 - val_loss: 0.0137 - val_mse: 3.9500e-04 - val_rmse: 0.0199 - val_mape: 15.3602\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0117 - mse: 3.1672e-04 - rmse: 0.0178 - mape: 9.5009 - val_loss: 0.0100 - val_mse: 2.3206e-04 - val_rmse: 0.0152 - val_mape: 7.3169\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0108 - mse: 2.8989e-04 - rmse: 0.0170 - mape: 6.5368 - val_loss: 0.0137 - val_mse: 4.2326e-04 - val_rmse: 0.0206 - val_mape: 12.0667\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0125 - mse: 3.7690e-04 - rmse: 0.0194 - mape: 11.7688 - val_loss: 0.0122 - val_mse: 2.9526e-04 - val_rmse: 0.0172 - val_mape: 8.2940\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0105 - mse: 2.8243e-04 - rmse: 0.0168 - mape: 7.0270 - val_loss: 0.0091 - val_mse: 2.0743e-04 - val_rmse: 0.0144 - val_mape: 7.6925\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0102 - mse: 2.5423e-04 - rmse: 0.0159 - mape: 9.4455 - val_loss: 0.0103 - val_mse: 2.1665e-04 - val_rmse: 0.0147 - val_mape: 13.5471\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0113 - mse: 2.6686e-04 - rmse: 0.0163 - mape: 12.4171 - val_loss: 0.0110 - val_mse: 2.5223e-04 - val_rmse: 0.0159 - val_mape: 10.1146\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0100 - mse: 2.2729e-04 - rmse: 0.0151 - mape: 7.3667 - val_loss: 0.0073 - val_mse: 1.3958e-04 - val_rmse: 0.0118 - val_mape: 7.8391\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0093 - mse: 2.0349e-04 - rmse: 0.0143 - mape: 7.3330 - val_loss: 0.0098 - val_mse: 1.8105e-04 - val_rmse: 0.0135 - val_mape: 23.3372\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0118 - mse: 2.5527e-04 - rmse: 0.0160 - mape: 19.2087 - val_loss: 0.0118 - val_mse: 2.2302e-04 - val_rmse: 0.0149 - val_mape: 23.8970\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0111 - mse: 2.3625e-04 - rmse: 0.0154 - mape: 17.8829 - val_loss: 0.0087 - val_mse: 1.3258e-04 - val_rmse: 0.0115 - val_mape: 15.7340\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0109 - mse: 2.5333e-04 - rmse: 0.0159 - mape: 14.4821 - val_loss: 0.0116 - val_mse: 2.9363e-04 - val_rmse: 0.0171 - val_mape: 9.2823\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0107 - mse: 2.7155e-04 - rmse: 0.0165 - mape: 12.0908 - val_loss: 0.0088 - val_mse: 1.4572e-04 - val_rmse: 0.0121 - val_mape: 15.7799\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0106 - mse: 2.4866e-04 - rmse: 0.0158 - mape: 13.2560 - val_loss: 0.0101 - val_mse: 2.3465e-04 - val_rmse: 0.0153 - val_mape: 7.6014\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0113 - mse: 2.7252e-04 - rmse: 0.0165 - mape: 12.6528 - val_loss: 0.0090 - val_mse: 1.6430e-04 - val_rmse: 0.0128 - val_mape: 5.8588\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0099 - mse: 2.1952e-04 - rmse: 0.0148 - mape: 5.3074 - val_loss: 0.0117 - val_mse: 3.0205e-04 - val_rmse: 0.0174 - val_mape: 15.4713\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0148 - mse: 5.0176e-04 - rmse: 0.0224 - mape: 12.6905 - val_loss: 0.0102 - val_mse: 2.7632e-04 - val_rmse: 0.0166 - val_mape: 9.5547\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0113 - mse: 2.9783e-04 - rmse: 0.0173 - mape: 9.3188 - val_loss: 0.0106 - val_mse: 2.5520e-04 - val_rmse: 0.0160 - val_mape: 6.5538\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0132 - mse: 4.6843e-04 - rmse: 0.0216 - mape: 7.8236 - val_loss: 0.0130 - val_mse: 3.1757e-04 - val_rmse: 0.0178 - val_mape: 11.8763\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0125 - mse: 3.4217e-04 - rmse: 0.0185 - mape: 11.3754 - val_loss: 0.0108 - val_mse: 2.0614e-04 - val_rmse: 0.0144 - val_mape: 21.6196\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0124 - mse: 3.5064e-04 - rmse: 0.0187 - mape: 13.5371 - val_loss: 0.0097 - val_mse: 2.0816e-04 - val_rmse: 0.0144 - val_mape: 12.7236\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0117 - mse: 2.7553e-04 - rmse: 0.0166 - mape: 13.2577 - val_loss: 0.0109 - val_mse: 2.9725e-04 - val_rmse: 0.0172 - val_mape: 12.1743\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0109 - mse: 2.8212e-04 - rmse: 0.0168 - mape: 13.4324 - val_loss: 0.0120 - val_mse: 2.9816e-04 - val_rmse: 0.0173 - val_mape: 14.7072\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0121 - mse: 2.9989e-04 - rmse: 0.0173 - mape: 13.6570 - val_loss: 0.0097 - val_mse: 1.8944e-04 - val_rmse: 0.0138 - val_mape: 13.8200\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0108 - mse: 2.4511e-04 - rmse: 0.0157 - mape: 10.2194 - val_loss: 0.0093 - val_mse: 1.5110e-04 - val_rmse: 0.0123 - val_mape: 17.4237\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0114 - mse: 2.9783e-04 - rmse: 0.0173 - mape: 14.4667 - val_loss: 0.0111 - val_mse: 2.6304e-04 - val_rmse: 0.0162 - val_mape: 9.8322\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0104 - mse: 2.3971e-04 - rmse: 0.0155 - mape: 10.8315 - val_loss: 0.0086 - val_mse: 1.4945e-04 - val_rmse: 0.0122 - val_mape: 16.8187\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0115 - mse: 2.6404e-04 - rmse: 0.0162 - mape: 16.8739 - val_loss: 0.0098 - val_mse: 1.9354e-04 - val_rmse: 0.0139 - val_mape: 15.4821\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0099 - mse: 2.0156e-04 - rmse: 0.0142 - mape: 16.8564 - val_loss: 0.0104 - val_mse: 2.3213e-04 - val_rmse: 0.0152 - val_mape: 13.7043\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0129 - mse: 3.2254e-04 - rmse: 0.0180 - mape: 21.5181 - val_loss: 0.0085 - val_mse: 1.6666e-04 - val_rmse: 0.0129 - val_mape: 10.5746\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0114 - mse: 2.3543e-04 - rmse: 0.0153 - mape: 22.2494 - val_loss: 0.0105 - val_mse: 1.9798e-04 - val_rmse: 0.0141 - val_mape: 13.6888\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0114 - mse: 2.4941e-04 - rmse: 0.0158 - mape: 22.4653 - val_loss: 0.0101 - val_mse: 1.6810e-04 - val_rmse: 0.0130 - val_mape: 26.8065\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0116 - mse: 2.5861e-04 - rmse: 0.0161 - mape: 21.2065 - val_loss: 0.0095 - val_mse: 2.0686e-04 - val_rmse: 0.0144 - val_mape: 23.1237\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0110 - mse: 2.3864e-04 - rmse: 0.0154 - mape: 20.2159 - val_loss: 0.0140 - val_mse: 3.2023e-04 - val_rmse: 0.0179 - val_mape: 30.1310\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0115 - mse: 2.5196e-04 - rmse: 0.0159 - mape: 17.2383 - val_loss: 0.0105 - val_mse: 1.9749e-04 - val_rmse: 0.0141 - val_mape: 11.8488\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0132 - mse: 3.1745e-04 - rmse: 0.0178 - mape: 15.9631 - val_loss: 0.0106 - val_mse: 2.7022e-04 - val_rmse: 0.0164 - val_mape: 14.7746\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0113 - mse: 2.7673e-04 - rmse: 0.0166 - mape: 13.4406 - val_loss: 0.0095 - val_mse: 1.8629e-04 - val_rmse: 0.0136 - val_mape: 14.7561\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0112 - mse: 2.6003e-04 - rmse: 0.0161 - mape: 11.1006 - val_loss: 0.0100 - val_mse: 2.2036e-04 - val_rmse: 0.0148 - val_mape: 7.8285\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0106 - mse: 2.5134e-04 - rmse: 0.0159 - mape: 10.3552 - val_loss: 0.0081 - val_mse: 1.9082e-04 - val_rmse: 0.0138 - val_mape: 5.6980\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0099 - mse: 2.1657e-04 - rmse: 0.0147 - mape: 9.2372 - val_loss: 0.0093 - val_mse: 1.7678e-04 - val_rmse: 0.0133 - val_mape: 6.3842\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0100 - mse: 2.2300e-04 - rmse: 0.0149 - mape: 11.0773 - val_loss: 0.0093 - val_mse: 1.6150e-04 - val_rmse: 0.0127 - val_mape: 11.8705\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0104 - mse: 2.4038e-04 - rmse: 0.0155 - mape: 11.3415 - val_loss: 0.0096 - val_mse: 1.9551e-04 - val_rmse: 0.0140 - val_mape: 11.7037\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0102 - mse: 2.2313e-04 - rmse: 0.0149 - mape: 9.9342 - val_loss: 0.0102 - val_mse: 2.2302e-04 - val_rmse: 0.0149 - val_mape: 14.0711\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0106 - mse: 2.4887e-04 - rmse: 0.0158 - mape: 11.5203 - val_loss: 0.0105 - val_mse: 2.4458e-04 - val_rmse: 0.0156 - val_mape: 5.4984\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0102 - mse: 2.6113e-04 - rmse: 0.0162 - mape: 5.3095 - val_loss: 0.0097 - val_mse: 2.1069e-04 - val_rmse: 0.0145 - val_mape: 9.6917\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0097 - mse: 2.1919e-04 - rmse: 0.0148 - mape: 5.9407 - val_loss: 0.0090 - val_mse: 2.1736e-04 - val_rmse: 0.0147 - val_mape: 3.6559\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0103 - mse: 2.2316e-04 - rmse: 0.0149 - mape: 10.5932 - val_loss: 0.0097 - val_mse: 1.6356e-04 - val_rmse: 0.0128 - val_mape: 23.7636\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0113 - mse: 2.3636e-04 - rmse: 0.0154 - mape: 17.7225 - val_loss: 0.0109 - val_mse: 2.0322e-04 - val_rmse: 0.0143 - val_mape: 20.8955\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0105 - mse: 2.2707e-04 - rmse: 0.0151 - mape: 12.0261 - val_loss: 0.0087 - val_mse: 1.4686e-04 - val_rmse: 0.0121 - val_mape: 9.6178\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0102 - mse: 2.3004e-04 - rmse: 0.0152 - mape: 7.5453 - val_loss: 0.0090 - val_mse: 1.7689e-04 - val_rmse: 0.0133 - val_mape: 5.4295\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0097 - mse: 2.1522e-04 - rmse: 0.0147 - mape: 7.6115 - val_loss: 0.0094 - val_mse: 2.2476e-04 - val_rmse: 0.0150 - val_mape: 4.5469\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0100 - mse: 2.4352e-04 - rmse: 0.0156 - mape: 5.0230 - val_loss: 0.0111 - val_mse: 2.7884e-04 - val_rmse: 0.0167 - val_mape: 4.7405\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0126 - mse: 3.8898e-04 - rmse: 0.0197 - mape: 4.7426\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "neurons = 14\n",
    "model, scaler, loss, history, cl_train, cd_train, cl_test, cd_test = ANN_model(X, y, neurons ,activation, loss_func, epoch, batch_size, validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4d6fd5f1-7053-42e8-9b64-af1a8ab57df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.012565634213387966,\n",
       " 0.00038898142520338297,\n",
       " 0.01972261071205139,\n",
       " 4.742570400238037]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a55382f5-10b5-475b-ada2-bd22e3b0aeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4113863753409093 6.199743665885333 3.7507094070109552 5.734430403528167\n"
     ]
    }
   ],
   "source": [
    "print (cl_train, cd_train, cl_test, cd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e04f8842-6faf-44f3-a905-5c315a7f7636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Validation_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a55523a3-78a9-49a2-ac16-36127b06ca97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_file__14_mae.joblib']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib.dump(model, 'model__14_mae.joblib')\n",
    "# joblib.dump(scaler, 'scaler_file__14_mae.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7073def9-248f-4507-b649-8c76df476dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
